{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyMVms12tTNXHm34ejHYnbHq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rVNu2R2WMwt9","executionInfo":{"status":"ok","timestamp":1752648767546,"user_tz":-540,"elapsed":16818,"user":{"displayName":"김용근","userId":"01220115268281105709"}},"outputId":"f0b9862e-c3ec-402a-cc4c-3ebf92b05aa4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at dataset\n"]}],"source":["# google drive mount\n","from google.colab import drive\n","drive.mount(\"dataset\", force_remount=True)"]},{"cell_type":"code","source":["# Pytorch install\n","!pip install torcheval\n","# create working directories\n","!mkdir /home/dataset\n","!mkdir /home/dataset/log\n","# copy the images into local directory\n","!cp -r /content/dataset/MyDrive/CNN_dataset/csi\\(1c\\)_AmFall_402_SDS_V0.10_O10_img_4.0  /home/dataset/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0EH74MTUM0J4","executionInfo":{"status":"ok","timestamp":1752649130155,"user_tz":-540,"elapsed":358856,"user":{"displayName":"김용근","userId":"01220115268281105709"}},"outputId":"5981bda8-fdce-42e9-eebd-3bcd088d0793"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torcheval\n","  Downloading torcheval-0.0.7-py3-none-any.whl.metadata (8.6 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torcheval) (4.14.1)\n","Downloading torcheval-0.0.7-py3-none-any.whl (179 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/179.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m153.6/179.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.2/179.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torcheval\n","Successfully installed torcheval-0.0.7\n"]}]},{"cell_type":"code","source":["# v3.3.1 : for multiple processing\n","#\n","# v3.3 : save options for the test results\n","#   - save test result information into log directory\n","#\n","# v3.2; save options for pth\n","# functions v3.1, for train/validation/test images from pre-defined log files\n","#   - output control for chatGPT process (3.1)\n","#   - bug fix for filename -7 -> -6\n","#   - data_organize_from_files() added\n","#\n","import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torch.utils.data import Dataset\n","from torchvision.io import read_image\n","from torchvision.transforms import ToTensor\n","import torch.optim as optim\n","from torchvision import transforms\n","from torchvision.models import  resnet18, ResNet18_Weights, \\\n","                                resnet34, ResNet34_Weights, \\\n","                                resnet50, ResNet50_Weights, \\\n","                                efficientnet_b0, EfficientNet_B0_Weights, \\\n","                                googlenet, GoogLeNet_Weights, \\\n","                                vgg16, VGG16_Weights, \\\n","                                shufflenet_v2_x0_5, ShuffleNet_V2_X0_5_Weights, \\\n","                                vgg16_bn, VGG16_BN_Weights, \\\n","                                inception_v3, Inception_V3_Weights\n","\n","from torcheval.metrics import BinaryConfusionMatrix # pip install torcheval\n","from torcheval.metrics.functional import binary_f1_score, binary_accuracy, binary_precision, binary_recall, binary_confusion_matrix\n","\n","import os\n","from os import path # path.join ('/', 'usr', 'lib') -> /usr/lib\n","import pandas as pd\n","import glob\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","import time\n","import datetime\n","\n","# basic utility functions\n","\n","LOG_DEBUG = 0\n","LOG_INFO = 1\n","LOG_SAVE = 2\n","LOG_WARNING = 3\n","LOG_ERROR = 4\n","LOG_CRITICAL = 5\n","\n","\n","# logging and printing function\n","class CSI_log :\n","    #def __new__(self): # called when the call is created, __new__ -> __init__\n","    #\n","    #  return super().__new__(self)\n","    def __init__(self, log_level=LOG_INFO, log_buf=\"\"): # called when the call is created, __new__ -> __init__\n","      self.log_buf = log_buf\n","      self.log_level = log_level\n","      self.log_results = \"\" # to print the summary results at the last stage (3.1)\n","      return super().__init__()\n","\n","    def set_log_level(self, log_level):\n","      self.log_level = log_level\n","\n","    def get_log_level(self):\n","      return self.log_level\n","\n","    def get_log_buf(self):\n","      return self.log_buf\n","\n","    def set_log_buf(self, log_buf):\n","      self.log_buf = log_buf\n","\n","    def set_log_results (self, log_results):\n","      self.log_results = log_results\n","\n","    def write (self, str, log_level=LOG_INFO, flag=True):\n","      if log_level >= self.log_level:\n","          self.log_buf += str\n","          if flag :\n","            print (str, end='')\n","\n","    def result (self, str, log_level=LOG_INFO, flag=False):\n","      if log_level >= self.log_level:\n","          self.log_results += str\n","          if flag :\n","            print (self.log_results + str)\n","\n","    def save(self, file_name):\n","      with open(file_name, 'w') as f:\n","        f.write(self.log_buf)\n","        f.write(self.log_results)\n","        f.close()\n","\n","csi_log = CSI_log()\n","\n","csi_log2 = CSI_log() # v3.3, to save the test result\n","\n","# global parameters\n","FALL=1\n","NONFALL=0\n","#SEP=os.sep # '/'\n","\n","device = (\n","    \"cuda\"\n","    if torch.cuda.is_available()\n","    else \"mps\"\n","    if torch.backends.mps.is_available()\n","    else \"cpu\"\n",")\n","print(f\"Using {device} device\")\n","\n","class CSI_ImageDataset(Dataset):\n","\n","    # 데이터셋의 전처리\n","    # img_files : full path\n","    # img_labels : 0 (Nonfall), 1 (Fall)\n","    def __init__(self, img_files, img_labels=None, ratio=0.8, train=True, \\\n","      random_seed=42, data_read=True, transform=None, target_transform=None):\n","        if img_labels is None :\n","          img_labels = [ NONFALL if (csi_img.find ('/fall/') == -1) else FALL for csi_img in img_files]\n","        if ratio == 1 :\n","          self.img_files = img_files\n","          self.labels = img_labels\n","        else :\n","          x_train, x_valid, y_train, y_valid = train_test_split(img_files, img_labels, \\\n","                      train_size=ratio, random_state=random_seed, \\\n","                      stratify=img_labels )\n","          if train :\n","            self.img_files = x_train\n","            self.labels = y_train\n","          else :\n","            self.img_files = x_valid\n","            self.labels = y_valid\n","\n","        self.data_read = data_read\n","        if data_read :\n","          self.images = [plt.imread(img) for img in self.img_files]\n","        self.transform = transform\n","        self.target_transform = target_transform\n","\n","    # 총 샘플의 수\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    # v 3.3 modification\n","    # 데이터셋에서 특정 1개의 샘플을 가져오는 함수\n","    def __getitem__(self, idx):\n","        if self.data_read : # already read\n","          image = self.images[idx]\n","          img_file = self.img_files[idx] # v3.3\n","        else :\n","          image = plt.imread(self.img_files[idx]) # self.images[idx]\n","          img_file = self.img_files[idx] # v3.3\n","\n","        label = self.labels[idx]\n","        if self.transform:\n","            image = self.transform(image)\n","        if self.target_transform:\n","            label = self.target_transform(label)\n","        return image, label, img_file # v3.3\n","\n","def train(dataloader, model, loss_fn, optimizer, scheduler):\n","    size = len(dataloader.dataset)\n","    model.train()\n","    #for batch, (X, y) in enumerate(dataloader):\n","    for batch, (X, y, files) in enumerate(dataloader):  # v3.3\n","        X, y = X.to(device), y.to(device)\n","        pred = model(X)\n","        if torch.is_tensor (pred) :\n","            loss = loss_fn(pred, y)\n","        else :\n","            loss = loss_fn(pred.logits, y) # for googlenet nontrained weight\n","        #loss = loss_fn(pred, y)\n","        optimizer.zero_grad() # 기울기 초기화\n","        loss.backward() # 역전파 (기울기 계산)\n","        optimizer.step() # 가중치 업데이트\n","    return\n","\n","# global variable to save the best trained model parameters\n","Best_model = None\n","Best_loss = 1_000_000.0\n","Best_epoch = 0\n","\n","def test(dataloader, model, loss_fn, epoch_n, best=False):\n","    global Best_model, Best_loss, Best_epoch\n","\n","    size = len(dataloader.dataset)\n","    num_batches = len(dataloader)\n","    model.eval()\n","    test_loss, correct = 0, 0\n","    TP, FN, FP, TN = 0, 0, 0, 0\n","    accuracy, precision, recall, F1 = 0, 0, 0, 0\n","\n","    with torch.no_grad(): # 리소스를  with문법을 통해 with 절 내에서만 액세스를 가능하게 하고, 블록을 나가는 경우 어떤 이유든간에 리소스를 해제\n","        #for X, y in dataloader: # check for (batch size) items each\n","        for X, y, files in dataloader: # v3.3, check for (batch size) items each\n","            X, y = X.to(device), y.to(device)\n","            if best:\n","              model.load_state_dict(Best_model)\n","              pred = model(X)\n","            else :\n","              pred = model(X)\n","            test_loss += loss_fn(pred, y).item()\n","            cm = binary_confusion_matrix(pred.argmax(1), y)\n","            TN += cm[0,0] # label(nonfall,0), pred(nonfall, 0)\n","            FP += cm[0,1] # label(nonfall,0), pred(fall,1)\n","            FN += cm[1,0] # label(fall, 1), pred(nonfall,0)\n","            TP += cm[1,1] # label(fall,1), pred(fall, 1)\n","            #v3.3\n","            preds = pred.argmax(1).cpu().numpy()\n","            labels = y.cpu().numpy()\n","            for i in range(len(preds)):\n","                file_name = files[i].rstrip('\\n');\n","                csi_log2.write (f\"{file_name}, {labels[i]}, {preds[i]}\\n\", flag=False)\n","\n","    accuracy = (TP+TN) / (TP+FP+FN+TN)\n","    precision = TP / (TP+FP)\n","    recall = TP / (TP+FN)\n","    F1 = 2*precision*recall / (precision+recall)\n","    test_loss /= num_batches\n","    if test_loss < Best_loss : # save the best estimated model with the minimum loss\n","        Best_loss = test_loss\n","        Best_model = model.state_dict()\n","        Best_epoch = epoch_n\n","    if best :\n","        csi_log.write (f\"*** Best model (epoch:{Best_epoch}) : \")\n","    global G_TP, G_FN, G_FP, G_TN\n","    G_TP = TP\n","    G_FN = FN\n","    G_FP = FP\n","    G_TN = TN\n","    csi_log.write (f\"Avg loss({test_loss:>5f}) : \")\n","    csi_log.write (f\"TP({TP}),FN({FN}),FP({FP}),TN({TN}) : \")\n","    csi_log.write (f\"Accuracy({accuracy:.5f}), Precision({precision:.5f}), Recall({recall:.5f}), F1({F1:.5f}) \\n\")\n","\n","\n","def train_test (model, train_dl, validation_dl, test_dl, loss_fn, optimizer, scheduler):\n","\n","  start_time = time.time()\n","\n","  for t in range(n_epochs):\n","      csi_log.write(f\"Epoch {t+1}, lr({optimizer.param_groups[0]['lr']}) : \")\n","      #if log_buf is not None :\n","      #  log_buf += f\"Epoch {t+1}, lr({optimizer.param_groups[0]['lr']}) : \"\n","\n","      train(train_dl, model, loss_fn, optimizer, scheduler)\n","      test(validation_dl, model, loss_fn, t+1)\n","      #print(\"lr: \", optimizer.param_groups[0]['lr'])\n","      scheduler.step()\n","  #global csi_log\n","  csi_log.write(\"==========================================\\n\")\n","  csi_log.write (\"Training Time: {:.4f}sec\\n\".format((time.time() - start_time)))\n","\n","  start_time = time.time()\n","  test(test_dl, model, loss_fn, t+1)\n","  test(test_dl, model, loss_fn, t+1, best=True)\n","\n","  csi_log.write (\"Inference Time: {:.4f}sec\\n\".format((time.time() - start_time)))\n","  #csi_log.write( \"==========================================\\n\")\n","  return\n","\n","\n","# data preparation\n","\n","LOSS_CE = 0\n","LOSS_BCE = 1\n","\n","OPT_ADAM = 0\n","OPT_SGDM = 1\n","OPT_ADAMW = 2\n","\n","OPT_WD = 0.0001 # OPT_PARM for adam\n","OPT_MNT = 0.9   # OPT_PARM for sgdm\n","\n","CNN_SNU1 = 0   # YKKIM's\n","CNN_SNU2 = 1  # SW's\n","CNN_SNU3 = 2  # SNU1 + Dropout\n","CNN_ENB0 = 3\n","CNN_ENB0_M = 4\n","CNN_R18 = 5\n","CNN_R34 = 6\n","CNN_GN = 7\n","CNN_ENB0_NPT = 8\n","CNN_ENB0_M_NPT = 9\n","CNN_R18_NPT = 10\n","CNN_R34_NPT = 11\n","CNN_GN_NPT = 12\n","CNN_SFNV2 = 13\n","CNN_SFNV2_NPT = 14\n","CNN_VGG16BN = 15\n","CNN_VGG16BN_NPT = 16\n","\n","cnn_model_name = [  \"SNU1\",     # 0; LW-CNN in AmFall paper\n","                    \"SNU2\",     # 1\n","                    \"SNU3\",     # 2\n","                    \"ENB0\",     # 3\n","                    \"ENB0_M\",   # 4\n","                    \"R18\",      # 5\n","                    \"R34\",      # 6\n","                    \"GN\",       # 7\n","                    \"ENB0_NPT\", # 8\n","                    \"ENB0_M_NPT\", # 9\n","                    \"R18_NPT\",    # 10\n","                    \"R34_NPT\",  # 11\n","                    \"GN_NPT\",   # 12\n","                    \"SFNV2\",    # 13\n","                    \"SFNV2_NPT\", # 14\n","                    \"VGG16BN\",  # 15\n","                    \"VGG16BN_NPT\" # 16\n","                 ]\n","##############################################\n","# default values\n","n_epochs = 5\n","n_batch_size = 50\n","initial_lr = 1e-3\n","f_shuffle = True\n","\n","# v3.3.1\n","G_TP = 0\n","G_FN = 0\n","G_FP = 0\n","G_TN = 0\n","\n","# n_epochs, n_batch_size, initial_lr, f_shuffle\n","hyper_parm_list = [\n","  [ 40, 50, 1e-3, True ], # HYPER0\n","  [ 40, 16, 1e-3, True ], # HYPER1\n","  [ 40, 16, 1e-4, True ], # HYPER2\n","  [ 40, 50, 1e-2, True], # HYPER3\n","  [ 45, 50, 1e-1, True], # HYPER4\n","  [ 40, 50, 1e-4, True], # HYPER5\n","  [ 40, 50, 1e-5, True], # HYPER6\n","  [ 40, 16, 1e-5, True], # HYPER7\n","  [ 80, 50, 1e-4, True], # HYPER8\n","  [ 40, 50, 1e-6, True], # HYPER9\n","  [ 50, 50, 1e-3, True], # HYPER10\n","  [ 8, 60, 1e-4, False] ] # HYPERn\n","HYPER0 = 0\n","HYPER1 = 1\n","HYPER2 = 2\n","HYPER3 = 3\n","HYPER4 = 4\n","HYPER5 = 5\n","HYPER6 = 6\n","HYPER7 = 7\n","HYPER8 = 8\n","HYPER9 = 9\n","HYPER10 = 10\n","\n","parameter_list = [\n","  # loss function, optimizer, optimizer parm, lr changes, lr gamma, f_shuffle\n","  [LOSS_CE, OPT_ADAM, OPT_WD, [ 10, 20, 30], 0.1], # PARM0\n","  [LOSS_CE, OPT_ADAM, 0.001, [ 10, 20, 30], 0.1], # PARM1\n","  [LOSS_CE, OPT_ADAM, 0.00001, [ 10, 20, 30], 0.1], # PARM2\n","  [LOSS_CE, OPT_ADAM, OPT_WD, [ 5, 10, 20, 30], 0.1], # PARM3\n","  [LOSS_CE, OPT_ADAM, OPT_WD, [ 5, 10, 15, 25, 35], 0.1], # PARM4\n","  [LOSS_CE, OPT_ADAM, OPT_WD, [ 20, 40, 60], 0.1], # PARM5\n","  [LOSS_CE, OPT_ADAM, OPT_WD, [ 20, 30, 40], 0.1], # PARM6\n","  [LOSS_CE, OPT_ADAM, OPT_WD, [ 10, 20, 30, 40 ], 0.1], # PARM7\n","  [LOSS_CE, OPT_ADAM, OPT_WD, [ 3, 6 ], 0.1]  # PARMn\n","  ]\n","PARM0 = 0\n","PARM1 = 1\n","PARM2 = 2\n","PARM3 = 3\n","PARM4 = 4\n","PARM5 = 5\n","PARM6 = 6\n","PARM7 = 7\n","\n","LOSS=0      # (0) CrossEntropy, (1) BinaryCrossEntropy\n","OPT=1       # (0) adam, (1) sdgm\n","OPT_PARM=2  # weight decay (adam), momentum (sdgm)\n","LR_STEP=3   # learning rate changes at [n, m]\n","LR_GAMMA=4  # lr change rate\n","\n","#root_dir = path.join('/content', 'dataset', 'MyDrive', 'CNN_dataset' )\n","#root_dir2 = None #path.join('/content', 'dataset', 'MyDrive', 'CNN_dataset' )\n","root_dir = path.join('/home', 'dataset')\n","root_dir2 = path.join('/content', 'dataset', 'MyDrive', 'CNN_dataset' )\n","\n","TRAIN = 0   # 'csi(1c)_img8_3_seg4_1'\n","TEST = 1    # 'csi(1c)_img8_3_seg4_1'\n","S_FN=2        # model file save name\n","CNN=3\n","HYPER=4\n","PARM=5\n","R_SEED=6\n","\n","##############################################\n","def hyper_parameter (idx=0):\n","  #global n_epochs, n_batch_size, initial_lr, f_shuffle\n","  #print(f\"{hyper_parm_list[idx][0]}, {hyper_parm_list[idx][1]}, {hyper_parm_list[idx][2]}, {hyper_parm_list[idx][3]}\")\n","  return hyper_parm_list[idx][0], hyper_parm_list[idx][1], hyper_parm_list[idx][2], hyper_parm_list[idx][3]\n","\n","################################################\n","\n","def loss_optimizer_scheduler (model, parm_idx=0): # hyper_parameter() should be called before this function\n","  parm_list = parameter_list[parm_idx]\n","  if parm_list[LOSS] == LOSS_CE :\n","    lf = nn.CrossEntropyLoss()\n","    csi_log.write (\"Loss function (CrossEntropy) \")\n","  elif parm_list[LOSS] == LOSS_BCE :\n","    lf = nn.BCELoss()()\n","    csi_log.write (\"Loss function (BCE) \")\n","\n","  if parm_list[OPT] == OPT_ADAM :\n","    opt = torch.optim.Adam(model.parameters(), lr=initial_lr, weight_decay = parm_list[OPT_PARM])\n","    csi_log.write (f\"opt (Adam, {parm_list[OPT_PARM]}) \")\n","  elif parm_list[OPT] == OPT_SGDM :\n","    opt = torch.optim.SGD(model.parameters(), lr=initial_lr, momentum = parm_list[OPT_PARM])\n","    csi_log.write (f\"opt (Sgdm, {parm_list[OPT_PARM]}) \")\n","  elif parm_list[OPT] == OPT_ADAMW :\n","    opt = torch.optim.AdamW(model.parameters(), lr=initial_lr, weight_decay = parm_list[OPT_PARM])\n","    csi_log.write (f\"opt (AdamW, {parm_list[OPT_PARM]}) \")\n","\n","  #scheduler\n","  sched = optim.lr_scheduler.MultiStepLR(opt, milestones=parm_list[LR_STEP], gamma=parm_list[LR_GAMMA])\n","  csi_log.write (f\"lr_scheduler (MultiStepLR), {parm_list[LR_STEP]}, gamma({parm_list[LR_GAMMA]})\\n\")\n","  return lf, opt, sched\n","################################################\n","# in data_organize(), the random_seed should be same for a data separation\n","def data_organize (e_list, data_transf, random_seed=21, check_valid=False): # hyper_parameter() should be called before this function\n","\n","  if e_list[TEST][0] == '' : # test directory is same as train/validation's\n","    csi_img_dir = path.join(root_dir, e_list[TRAIN][0] )\n","    csi_img_files = path.join(csi_img_dir, e_list[TRAIN][1] )\n","    csi_img_files = glob.glob(csi_img_files, recursive=True)\n","    csi_labels = [ NONFALL if (csi_img.find ('/fall/') == -1) else FALL for csi_img in csi_img_files]\n","\n","    train_valid_ds = CSI_ImageDataset(csi_img_files, csi_labels, ratio=0.8, \\\n","                        train=True, data_read=False, random_seed=random_seed)\n","    test_ds = CSI_ImageDataset(csi_img_files, csi_labels, ratio=0.8, \\\n","                        train=False, data_read=True, transform = data_transf, \\\n","                        random_seed=random_seed)\n","    validation_ds = CSI_ImageDataset(train_valid_ds.img_files, train_valid_ds.labels, \\\n","                        ratio=0.85, train=False, data_read=True, \\\n","                        transform = data_transf, random_seed=random_seed)\n","    train_ds = CSI_ImageDataset(train_valid_ds.img_files, train_valid_ds.labels, \\\n","                        ratio=0.85, train=True, data_read=True, \\\n","                        transform = data_transf, random_seed=random_seed)\n","\n","  else : # test directory is different from that of train/validation's\n","    # separation of train and validation\n","    csi_img_dir = path.join(root_dir, e_list[TRAIN][0] )\n","    csi_img_files = path.join(csi_img_dir, e_list[TRAIN][1] )\n","    csi_img_files = glob.glob(csi_img_files, recursive=True)\n","    csi_labels = [ NONFALL if (csi_img.find ('/fall/') == -1) else FALL for csi_img in csi_img_files]\n","\n","    validation_ds = CSI_ImageDataset(csi_img_files, csi_labels, ratio=0.85, train=False, \\\n","                        data_read=True, transform = data_transf, random_seed=random_seed)\n","    train_ds = CSI_ImageDataset(csi_img_files, csi_labels, ratio=0.85, train=True, \\\n","                        data_read=True, transform = data_transf, random_seed=random_seed)\n","\n","    # compose test\n","    csi_img_dir = path.join(root_dir, e_list[TEST][0] )\n","    csi_img_files = path.join(csi_img_dir, e_list[TEST][1] )\n","    csi_img_files = glob.glob(csi_img_files, recursive=True)\n","    csi_labels = [ NONFALL if (csi_img.find ('/fall/') == -1) else FALL for csi_img in csi_img_files]\n","    test_ds = CSI_ImageDataset(csi_img_files, csi_labels, ratio=1, train=True, \\\n","                        data_read=True, transform = data_transf, random_seed=random_seed)\n","\n","  # check if the data separation is done correctly (i.e., no duplicated file names)\n","  sep_result = True\n","  if check_valid :\n","    for i in range(len(train_ds)) :\n","        if train_ds.img_files[i] in validation_ds.img_files or train_ds.img_files[i] in test_ds.img_files :\n","          sep_result = False\n","          break\n","    if sep_result :\n","        for i in range (len(validation_ds)) :\n","          if validation_ds.img_files[i] in test_ds.img_files :\n","            sep_result = False\n","            break\n","\n","  return train_ds, validation_ds, test_ds, sep_result\n","\n","################################################\n","\n","def data_organize_from_file (e_list, data_transf, file_name, search_flag=False, random_seed=21, check_valid=False): # hyper_parameter() should be called before this function\n","    # train_file is the name of (1C), then, the actual image files are in 35C or 70C\n","    # validation_file and test_file are supposed to be in a same directory\n","    with open(file_name, 'r') as f:\n","        img_lines = f.readlines()\n","        f.close()\n","\n","    # the image file needs to have full path\n","    csi_img_files = []\n","    for img in img_lines :\n","        if search_flag : # for nC image directory\n","            img = os.path.basename(img)\n","            #img = img[0:len(img)-7] # 파일명은 _1.jpg 가 된다. It is a bug in 2.0\n","            img = img[0:len(img)-6] # 파일명은 _1.jpg 가 된다.\n","            #print(f\"{e_list[TRAIN][1]}\")\n","            img_dir = path.join(root_dir, e_list[TRAIN][0] )\n","            # updated on 01JUL24, os.path.dirname(a)\n","            #search_str = path.join(img_dir, '*/*/*/'+img+'*.jpg')\n","            search_str = path.join(img_dir, os.path.dirname(e_list[TRAIN][1]), img+'*.jpg')\n","            imgs = glob.glob(search_str, recursive=True)\n","            #print (imgs)\n","            csi_img_files += imgs\n","        else:\n","            # for 1C image directory, don't need to find it\n","            # just use it as full path file name\n","            #print (img.strip())\n","            csi_img_files.append(img.strip())\n","    #print (csi_img_files)\n","    csi_labels = [ NONFALL if (csi_img.find ('/fall/') == -1) else FALL for csi_img in csi_img_files]\n","    data_ds = CSI_ImageDataset(csi_img_files, csi_labels, \\\n","                        ratio=1, train=True, data_read=True, \\\n","                        transform = data_transf, random_seed=random_seed)\n","    return data_ds\n","\n","################################################\n","\n","class SNU1_cnn (nn.Module) : # SNU CNN module defition, by ykkim\n","    def __init__(self):\n","        super(SNU1_cnn, self).__init__()  #  생성자 제일 앞에 super() 함수를 호출하고(그렇지 않으면 에러가 발생합니다), 사용할 모듈들을 인스턴스 변수로 초기화합니다\n","        self.layer1 = nn.Sequential(\n","            nn.Conv2d(3, 8, kernel_size=3, stride=1, padding='same'),\n","            nn.BatchNorm2d (8),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, stride=2) # stride = kernel size (by default)\n","        )\n","        self.layer2 = nn.Sequential(\n","            nn.Conv2d(8, 16, kernel_size=3, stride=1, padding='same'),\n","            nn.BatchNorm2d (16),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, stride=2) # stride = kernel size (by default)\n","        )\n","        self.layer3 = nn.Sequential(\n","            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding='same'),\n","            nn.BatchNorm2d (32),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, stride=2) # stride = kernel size (by default)\n","        )\n","        self.fc = nn.Linear(in_features=25088, out_features=2, bias=True)\n","        self.softmax = nn.Softmax(dim=1)\n","\n","\n","    def forward(self, x): # forward 메서드는 입력 데이터가 주어졌을 때 선언한 인스턴스 변수(모듈)들을 통과해 출력 데이터를 만드는 메서드\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = torch.flatten(x,1) # x=torch.flatten(x,1), only batches of spatial targets supported (3D tensors) but got targets of dimension: 1\n","        x = self.fc(x)\n","        x = self.softmax(x)\n","        return x\n","\n","class SNU3_cnn (nn.Module) : # SNU1 + Dropout layer CNN module defition, by ykkim\n","    def __init__(self):\n","        super(SNU3_cnn, self).__init__()  #  생성자 제일 앞에 super() 함수를 호출하고(그렇지 않으면 에러가 발생합니다), 사용할 모듈들을 인스턴스 변수로 초기화합니다\n","        self.layer1 = nn.Sequential(\n","            nn.Conv2d(3, 8, kernel_size=3, stride=1, padding='same'),\n","            nn.BatchNorm2d (8),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, stride=2) # stride = kernel size (by default)\n","        )\n","        self.layer2 = nn.Sequential(\n","            nn.Conv2d(8, 16, kernel_size=3, stride=1, padding='same'),\n","            nn.BatchNorm2d (16),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, stride=2) # stride = kernel size (by default)\n","        )\n","        self.layer3 = nn.Sequential(\n","            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding='same'),\n","            nn.BatchNorm2d (32),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, stride=2) # stride = kernel size (by default)\n","        )\n","        self.dropout = nn.Dropout(p=0.5, inplace=False) # default\n","        self.fc = nn.Linear(in_features=25088, out_features=2, bias=True)\n","        self.softmax = nn.Softmax(dim=1)\n","\n","\n","    def forward(self, x): # forward 메서드는 입력 데이터가 주어졌을 때 선언한 인스턴스 변수(모듈)들을 통과해 출력 데이터를 만드는 메서드\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = torch.flatten(x,1) # x=torch.flatten(x,1), only batches of spatial targets supported (3D tensors) but got targets of dimension: 1\n","        x = self.dropout(x)\n","        x = self.fc(x)\n","        x = self.softmax(x)\n","        return x\n","\n","class SNU2_cnn (nn.Module) : # SNU CNN module defition, by swjang\n","    def __init__(self):\n","        super(SNU2_cnn, self).__init__()\n","        self.layer1 = nn.Sequential(\n","            nn.Conv2d(3, 64, kernel_size=7, stride=1, padding='same'),\n","            nn.LeakyReLU(),\n","            nn.MaxPool2d(2, stride=2) # stride = kernel size (by default)\n","        )\n","        self.layer2 = nn.Sequential(\n","            nn.Conv2d(64, 128, kernel_size=5, stride=1, padding='same'),\n","            nn.LeakyReLU(),\n","            nn.MaxPool2d(2, stride=2) # stride = kernel size (by default)\n","        )\n","        self.layer3 = nn.Sequential(\n","            nn.Conv2d(128, 128, kernel_size=5, stride=1, padding='same'),\n","            nn.LeakyReLU(),\n","            nn.MaxPool2d(2, stride=2) # stride = kernel size (by default)\n","        )\n","        self.layer4 = nn.Sequential(\n","            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding='same'),\n","            nn.LeakyReLU(),\n","            nn.BatchNorm2d (128, momentum=0.5)\n","        )\n","        # Flatten will be done inbetween, in forward function\n","        self.layer5 = nn.Sequential(\n","            nn.Dropout(p=0.5, inplace=False), # default\n","            nn.Linear(in_features=100352, out_features=64, bias=True),\n","            nn.LeakyReLU(),\n","            nn.Dropout(p=0.5, inplace=False), # default\n","            nn.Linear(in_features=64, out_features=2, bias=True)\n","        )\n","        #self.softmax = nn.Softmax(dim=1)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x): # forward 메서드는 입력 데이터가 주어졌을 때 선언한 인스턴스 변수(모듈)들을 통과해 출력 데이터를 만드는 메서드\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        x = torch.flatten(x,1) # x=torch.flatten(x,1), only batches of spatial targets supported (3D tensors) but got targets of dimension: 1\n","        x = self.layer5(x)\n","        x = self.sigmoid(x)\n","        return x\n","\n","\n","def cnn_model (cnn_idx=0):\n","  weights = None\n","  model = None\n","  global device\n","\n","  if cnn_idx == CNN_ENB0 :\n","    weights = EfficientNet_B0_Weights.DEFAULT\n","    model = efficientnet_b0(weights=weights) # model = efficientnet_b0(weights=None) # TBC\n","    model.classifier[1] = nn.Linear(in_features=1280, out_features=2, bias=True)\n","  elif cnn_idx == CNN_ENB0_M :\n","    weights = EfficientNet_B0_Weights.DEFAULT\n","    model = efficientnet_b0(weights=weights) # model = efficientnet_b0(weights=None) # TBC\n","    model.classifier = nn.Sequential(\n","        nn.Linear(in_features=1280, out_features=512, bias=True),\n","        nn.SiLU(),\n","        nn.Dropout(p=0.5, inplace=False), # default\n","        nn.Linear(in_features=512, out_features=256, bias=True),\n","        nn.SiLU(),\n","        nn.Dropout(p=0.5, inplace=False), # default\n","        nn.Linear(in_features=256, out_features=2, bias=True),\n","        nn.SiLU()\n","    )\n","  elif cnn_idx == CNN_SNU1 : # ykkim's\n","    model = SNU1_cnn()\n","  elif cnn_idx == CNN_SNU2 : # ykkim's\n","    model = SNU2_cnn()\n","  elif cnn_idx == CNN_SNU3 : # ykkim's\n","    model = SNU3_cnn()\n","  elif cnn_idx == CNN_R18 : # R18 pretrained\n","    weights = ResNet18_Weights.DEFAULT\n","    model = resnet18 (weights=weights)\n","    model.fc = nn.Linear(in_features=512, out_features=2, bias=True)\n","  elif cnn_idx == CNN_R34 : # R34 pretrained\n","    weights = ResNet34_Weights.DEFAULT\n","    model = resnet34 (weights=weights)\n","    model.fc = nn.Linear(in_features=512, out_features=2, bias=True)\n","  elif cnn_idx == CNN_GN : # GN pretrained\n","    weights = GoogLeNet_Weights.DEFAULT\n","    model = googlenet (weights=weights)\n","    model.fc = nn.Linear(in_features=1024, out_features=2, bias=True)\n","  elif cnn_idx == CNN_R18_NPT : # R18 not pretrained (model only)\n","    #weights = ResNet18_Weights.DEFAULT # to use transforms() only\n","    model = resnet18 ()\n","    model.fc = nn.Linear(in_features=512, out_features=2, bias=True)\n","  elif cnn_idx == CNN_R34_NPT : # R34 not pretrained (model only)\n","    #weights = ResNet34_Weights.DEFAULT # to use transforms() only\n","    model = resnet34 ()\n","    model.fc = nn.Linear(in_features=512, out_features=2, bias=True)\n","  elif cnn_idx == CNN_GN_NPT : # GN not pretrained (model only)\n","    #weights = GoogLeNet_Weights.DEFAULT # to use transforms() only\n","    model = googlenet ()\n","    model.fc = nn.Linear(in_features=1024, out_features=2, bias=True)\n","  elif cnn_idx == CNN_ENB0_NPT :\n","    #weights = EfficientNet_B0_Weights.DEFAULT # to use transforms() only\n","    model = efficientnet_b0() # model = efficientnet_b0(weights=None) # TBC\n","    model.classifier[1] = nn.Linear(in_features=1280, out_features=2, bias=True)\n","  elif cnn_idx == CNN_ENB0_M_NPT :\n","    #weights = EfficientNet_B0_Weights.DEFAULT # to use transforms() only\n","    model = efficientnet_b0() # model = efficientnet_b0(weights=None) # TBC\n","    model.classifier = nn.Sequential(\n","        nn.Linear(in_features=1280, out_features=512, bias=True),\n","        nn.SiLU(),\n","        nn.Dropout(p=0.5, inplace=False), # default\n","        nn.Linear(in_features=512, out_features=256, bias=True),\n","        nn.SiLU(),\n","        nn.Dropout(p=0.5, inplace=False), # default\n","        nn.Linear(in_features=256, out_features=2, bias=True),\n","        nn.SiLU()\n","    )\n","  elif cnn_idx == CNN_SFNV2 : # SFNV2 pretrained\n","    weights = ShuffleNet_V2_X0_5_Weights.DEFAULT\n","    model = shufflenet_v2_x0_5 (weights=weights)\n","    model.fc = nn.Linear(in_features=1024, out_features=2, bias=True)\n","  elif cnn_idx == CNN_SFNV2_NPT : # SFNV2 not pretrained (model only)\n","    #weights = ShuffleNet_V2_x0_5_Weights.DEFAULT\n","    model = shufflenet_v2_x0_5 ()\n","    model.fc = nn.Linear(in_features=1024, out_features=2, bias=True)\n","  elif cnn_idx == CNN_VGG16BN : # VGG16BN pretrained\n","    weights = VGG16_BN_Weights.DEFAULT\n","    model = vgg16_bn (weights=weights)\n","    model.classifier[6] = nn.Linear(in_features=4096, out_features=2, bias=True)\n","  elif cnn_idx == CNN_VGG16BN_NPT : # VGG16BN not pretrained (model only)\n","    model = vgg16_bn ()\n","    model.classifier[6] = nn.Linear(in_features=4096, out_features=2, bias=True)\n","\n","  if device == \"cuda\" :\n","    model.cuda()\n","  return model, weights\n","\n","# v3.2, %S included\n","def save_model (model, s_file, root_dir, root_dir2 = None, ds_save=True, model_save=True):\n","  now = datetime.datetime.now()\n","\n","  save_file_name = path.join(root_dir,'log', s_file) + '_' + now.strftime(\"%m%d%H%M%S\")\n","  torch.save(model.state_dict(), save_file_name + '.pth')\n","  #global csi_log\n","  csi_log.write (f\"saved model name : {save_file_name}\\n\")\n","  # new addition\n","  global G_TP, G_FN, G_FP, G_TN\n","  csi_log.write (f\"{G_TP}, {G_FN}, {G_FP}, {G_TN}, {os.path.basename(save_file_name)}\\n\") # added for save convenience\n","  csi_log.result (f\"{G_TP}\\t{G_FN}\\t{G_FP}\\t{G_TN}\\t{os.path.basename(save_file_name)}\\n\") # v3.1\n","  csi_log.write (\"----------------------------------------------------\\n\")\n","  #if log_buf is not None :\n","  #  log_buf += local_buf + ''\n","  csi_log.save (save_file_name + '.log')\n","\n","  if Best_model is not None:\n","    save_file_name = path.join(root_dir,'log', 'Best_model') + '_' + now.strftime(\"%m%d%H%M%S\")\n","    if model_save :\n","        torch.save(Best_model, save_file_name + '_best.pth')\n","\n","  if root_dir2 is not None :\n","    save_file_name = path.join(root_dir2, 'log', s_file) + '_' + now.strftime(\"%m%d%H%M%S\")\n","    if model_save :\n","        torch.save(model.state_dict(), save_file_name + '.pth')\n","    if Best_model is not None:\n","      if model_save :\n","          torch.save(Best_model, save_file_name + '_best.pth')\n","    csi_log.save (save_file_name + '.log')\n","  #print (local_buf+'----------------------------')\n","\n","  global train_ds, validation_ds, test_ds\n","\n","  if ds_save :\n","      train_file_str = \"\"\n","      for img in train_ds.img_files :\n","          train_file_str += img + '\\n'\n","      validation_file_str = \"\"\n","      for img in validation_ds.img_files :\n","          validation_file_str += img + '\\n'\n","      test_file_str = \"\"\n","      for img in test_ds.img_files :\n","          test_file_str += img + '\\n'\n","\n","      train_file = path.join(root_dir, 'log', s_file) + '_' + now.strftime(\"%m%d%H%M%S\") + '_train.log'\n","      validation_file = path.join(root_dir, 'log', s_file) + '_' + now.strftime(\"%m%d%H%M%S\") + '_validation.log'\n","      test_file = path.join(root_dir, 'log', s_file) + '_' + now.strftime(\"%m%d%H%M%S\") + '_test.log'\n","\n","      with open(train_file, 'w') as f:\n","        f.write(train_file_str)\n","        f.close()\n","      with open(validation_file, 'w') as f:\n","        f.write(validation_file_str)\n","        f.close()\n","      with open(test_file, 'w') as f:\n","        f.write(test_file_str)\n","        f.close()\n","\n","      csi_log2.save (save_file_name + '_test_result.log') # v3.3\n","\n","      if root_dir2 is not None :\n","          train_file = path.join(root_dir2, 'log',s_file) + '_' + now.strftime(\"%m%d%H%M%S\") + '_train.log'\n","          validation_file = path.join(root_dir2, 'log', s_file) + '_' + now.strftime(\"%m%d%H%M%S\") + '_validation.log'\n","          test_file = path.join(root_dir2, 'log', s_file) + '_' + now.strftime(\"%m%d%H%M%S\") + '_test.log'\n","          with open(train_file, 'w') as f:\n","              f.write(train_file_str)\n","              f.close()\n","          with open(validation_file, 'w') as f:\n","            f.write(validation_file_str)\n","            f.close()\n","          with open(test_file, 'w') as f:\n","            f.write(test_file_str)\n","            f.close()\n","  return save_file_name\n","\n","def load_model (model, file_path):\n","  model.load_state_dict(torch.load(file_path))\n","  csi_log.write( f\"loaded model name : {file_path}\\n\" )\n","  return model\n","\n","def load_test_model (model, loss_fn, file_path, test_dl):\n","  model = load_model (model, file_path)\n","  test(test_dl, model, loss_fn)\n","  return model\n","\n"],"metadata":{"id":"aQYotHxGM0ho","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752648050030,"user_tz":-540,"elapsed":10911,"user":{"displayName":"김용근","userId":"01220115268281105709"}},"outputId":"ef72e3bd-eda0-4fdd-b72b-235c596727d7"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Using cuda device\n"]}]},{"cell_type":"code","source":["# v3.3.1 : csi_log2.set_log_buf(\"\")\n","# 1X test (PhaFall 2.3.2), previous LPD and csi_HiS instead of max abs\n","\n","from pickle import TRUE\n","## main version 3.1,\n","\n","import copy\n","\n","def execute_cnn (execution_list, file_read_flag = False, nX_read_flag = False ):\n","\n","    global train_ds, validation_ds, test_ds\n","    global n_epochs, n_batch_size, initial_lr, f_shuffle\n","    global csi_log, csi_log2\n","\n","    csi_log.set_log_buf (\"\")\n","    csi_log.set_log_results (\"\")\n","    csi_log2.set_log_buf (\"\")\n","    csi_log2.set_log_results (\"\")\n","\n","    csi_log.write(f\"Processed on {device}...\\n\")\n","    i_count = 0;\n","\n","    for ie in range( len(execution_list)) :\n","      i_count += 1\n","      print (f\"Progress : [{i_count}/{len(execution_list)}]\\n\")\n","\n","      e_list = execution_list[ie]\n","      n_epochs, n_batch_size, initial_lr, f_shuffle = hyper_parameter(e_list[HYPER])\n","      csi_log.write (f\"******* {e_list[S_FN]}, Train({e_list[TRAIN]}), Test ({e_list[TEST]}), epoch ({n_epochs}), bs ({n_batch_size}), lr ({initial_lr}), shuffle({f_shuffle}) \\n\")\n","\n","      if isinstance (e_list[CNN], list): # if it is a list (multiple CNN models for the above dataset)\n","        e_cnn =  e_list[CNN]\n","      else : # a sigle entry\n","        e_cnn =  [ e_list[CNN] ] # make it as list\n","\n","      for im in range (len (e_cnn)) :  # there are multiple CNN models for the above dataset\n","          global Best_model, Best_loss, Best_epoch\n","\n","          Best_model = None\n","          Best_loss = 1_000_000.0\n","          Best_epoch = 0\n","\n","          csi_log.write(f\"CNN ({cnn_model_name[e_cnn[im]]})\\n\")\n","          model, weights = cnn_model (e_cnn[im])\n","\n","          loss_fn, optimizer, scheduler = loss_optimizer_scheduler (model, e_list[PARM])\n","\n","          if weights is None :\n","              data_transf = transforms.Compose([transforms.ToPILImage(), transforms.ToTensor()])\n","          else :\n","            data_transf = transforms.Compose([transforms.ToPILImage(), transforms.ToTensor(), weights.transforms()])\n","\n","          if file_read_flag : # read image file names from the desiginated file\n","              #train_file = path.join(root_dir, 'log', e_list[TRAIN]) + '.log'\n","\n","              train_ds = data_organize_from_file (e_list, data_transf,\\\n","                      Train_log_file, search_flag=True, random_seed=e_list[R_SEED] )\n","              #validation_ds = data_organize_from_file (e_list, data_transf,\\\n","              #        Validation_log_file, search_flag=False, random_seed=e_list[R_SEED] )\n","              validation_ds = data_organize_from_file (e_list, data_transf,\\\n","                      Validation_log_file, search_flag=True, random_seed=e_list[R_SEED] )\n","              test_ds = data_organize_from_file (e_list, data_transf,\\\n","                      Test_log_file, search_flag=False, random_seed=e_list[R_SEED] )\n","              csi_log.write (f\"Train ({len(train_ds)}), Validation ({len(validation_ds)}), Test ({len(test_ds)})\\n\")\n","          else :\n","\n","              if nX_read_flag :           # 3.0 updates\n","                  # split data into train_ds, validation_ds, test_ds from the desiginated directory\n","                  # compose temp_e_list\n","                  temp_e_list = copy.deepcopy(e_list)\n","                  temp_e_list[TRAIN][0] = e_list[TEST][0]\n","                  temp_e_list[TEST][0] = '' # path.join ('')\n","                  train_ds, validation_ds, test_ds, sep_result = data_organize(temp_e_list, data_transf,\\\n","                                                random_seed=e_list[R_SEED], check_valid=True )\n","                  # save each train_da, validation_da, test_ds.img_files into temp files\n","                  train_file_str = \"\"\n","                  for img in train_ds.img_files :\n","                      train_file_str += img + '\\n'\n","                  validation_file_str = \"\"\n","                  for img in validation_ds.img_files :\n","                      validation_file_str += img + '\\n'\n","                  test_file_str = \"\"\n","                  for img in test_ds.img_files :\n","                      test_file_str += img + '\\n'\n","\n","                  with open(\"train_file\", 'w') as f:\n","                    f.write(train_file_str)\n","                    f.close()\n","                  with open(\"validation_file\", 'w') as f:\n","                    f.write(validation_file_str)\n","                    f.close()\n","                  with open(\"test_file\", 'w') as f:\n","                    f.write(test_file_str)\n","                    f.close()\n","                  # release train_ds, validation_ds, then compose new train_da, validation_da\n","                  del train_ds, validation_ds\n","                  train_ds = data_organize_from_file (e_list, data_transf,\\\n","                          \"train_file\", search_flag=True, random_seed=e_list[R_SEED] )\n","                  validation_ds = data_organize_from_file (e_list, data_transf,\\\n","                        \"validation_file\", search_flag=False, random_seed=e_list[R_SEED] )\n","\n","              else :\n","                  #r_seed = e_list[R_SEED]\n","                  train_ds, validation_ds, test_ds, sep_result = data_organize(e_list, data_transf,\\\n","                                                  random_seed=e_list[R_SEED], check_valid=True )\n","                                                  #random_seed=(ie+1), check_valid=True )\n","              csi_log.write(f\"random_seed ({e_list[R_SEED]}, nX_read_flag ({nX_read_flag})\\n\")\n","\n","              if sep_result :\n","                csi_log.write (f\"Train ({len(train_ds)}), Validation ({len(validation_ds)}), Test ({len(test_ds)})\\n\")\n","              else :\n","                csi_log.write (\"data separation is NOT done correctly\\n\")\n","\n","          # shuffle=True 로 지정했으므로, 모든 배치를 순회한 뒤 데이터가 섞임\n","          train_dl = DataLoader(train_ds, batch_size=n_batch_size, shuffle=f_shuffle)\n","          test_dl = DataLoader(test_ds, batch_size=n_batch_size, shuffle=f_shuffle)\n","          validation_dl = DataLoader(validation_ds, batch_size=n_batch_size, shuffle=f_shuffle)\n","\n","          train_test(model, train_dl, validation_dl, test_dl, loss_fn, optimizer, scheduler)\n","\n","          s_file = cnn_model_name[e_cnn[im]] + '_'+ e_list[S_FN] + \\\n","              '_H' + str(e_list[HYPER]) + '_P' + str(e_list[PARM])+'_R' + str(e_list[R_SEED])\n","          s_file = save_model (model, s_file, root_dir, root_dir2, ds_save=True, model_save=False) # v3.2\n","          csi_log.set_log_buf(\"\")\n","          csi_log2.set_log_buf(\"\") # v3.3.1\n","          del model, loss_fn, optimizer, scheduler, train_ds, validation_ds, test_ds, train_dl, test_dl, validation_dl\n","          if device == \"cuda\" :\n","            torch.cuda.empty_cache()\n","\n","      #if (i_count % 3) == 0 :\n","      #  csi_log.result(\"\", flag=True)\n","      #  csi_log.set_log_results (\"\")\n","\n","    csi_log.result(\"\", flag=True) # print the all result strings, v3.1\n"],"metadata":{"id":"eQWS6sKEzj6E","executionInfo":{"status":"ok","timestamp":1752648063085,"user_tz":-540,"elapsed":8,"user":{"displayName":"김용근","userId":"01220115268281105709"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["random_seed = 31 # 31 or 42, 5\n","random_seed2 = 42\n","random_seed3 = 5\n","\n","file_read_flag = False # Set True if the file separation is necessary, and Train_log_file, Validation_log_file, Test_log_file are\n","                      # used to get images from the file\n","nX_read_flag = False  # Set True if nX data is read after random split of the desinated directory (that is csi_img_dir2)\n","if nX_read_flag :\n","  file_read_flag = False\n","\n","iteration_list = [ 1 ]\n","\n","csi_img_dir_train = 'csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0'\n","csi_img_dir_test = 'csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0'\n","\n","CNN_MODEL = CNN_SNU1\n","\n","for iteration in iteration_list :\n","\n","    execution_list=[\n","      [ [ path.join (csi_img_dir_train, 'enva'), path.join ('*','*','*.jpg') ],\n","        [ '', '' ],\n","        csi_img_dir_train+'_A_A',\n","        [ CNN_MODEL, CNN_MODEL ],\n","        HYPER5, PARM0, random_seed ]\n","      ,\n","      [ [ path.join (csi_img_dir_train, 'enva'), path.join ('*','*','*.jpg') ],\n","        [ '', '' ],\n","        csi_img_dir_train+'_A_A',\n","        [ CNN_MODEL, CNN_MODEL ],\n","        HYPER5, PARM0, random_seed2 ]\n","      ,\n","      [ [ path.join (csi_img_dir_train, 'enva'), path.join ('*','*','*.jpg') ],\n","        [ '', '' ],\n","        csi_img_dir_train+'_A_A',\n","        [ CNN_MODEL, CNN_MODEL ],\n","        HYPER5, PARM0, random_seed3 ]\n","    ]\n","\n","    execute_cnn (execution_list, file_read_flag = file_read_flag, nX_read_flag = nX_read_flag  )\n","\n","CNN_MODEL = CNN_R18\n","\n","for iteration in iteration_list :\n","\n","    execution_list=[\n","      [ [ path.join (csi_img_dir_train, 'envb'), path.join ('*','*','*.jpg') ],\n","        [ path.join (csi_img_dir_test, 'enva'), path.join ('*','*','*.jpg') ],\n","        csi_img_dir_train+'_B_A',\n","        [ CNN_MODEL, CNN_MODEL ],\n","        HYPER5, PARM0, random_seed ]\n","      ,\n","      [ [ path.join (csi_img_dir_train, 'envb'), path.join ('*','*','*.jpg') ],\n","        [ path.join (csi_img_dir_test, 'enva'), path.join ('*','*','*.jpg') ],\n","        csi_img_dir_train+'_B_A',\n","        [ CNN_MODEL, CNN_MODEL ],\n","        HYPER5, PARM0, random_seed2 ]\n","      ,\n","      [ [ path.join (csi_img_dir_train, 'envb'), path.join ('*','*','*.jpg') ],\n","        [ path.join (csi_img_dir_test, 'enva'), path.join ('*','*','*.jpg') ],\n","        csi_img_dir_train+'_B_A',\n","        [ CNN_MODEL, CNN_MODEL ],\n","        HYPER5, PARM0, random_seed3 ]\n","    ]\n","\n","    execute_cnn (execution_list, file_read_flag = file_read_flag, nX_read_flag = nX_read_flag  )\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I6TpmCQv31KV","executionInfo":{"status":"ok","timestamp":1752648499007,"user_tz":-540,"elapsed":379240,"user":{"displayName":"김용근","userId":"01220115268281105709"}},"outputId":"b04ed555-4695-461a-9880-73772bd3ae6a"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Processed on cuda...\n","Progress : [1/3]\n","\n","******* csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0_A_A, Train(['csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0/enva', '*/*/*.jpg']), Test (['', '']), epoch (40), bs (50), lr (0.0001), shuffle(True) \n","CNN (SNU1)\n","Loss function (CrossEntropy) opt (Adam, 0.0001) lr_scheduler (MultiStepLR), [10, 20, 30], gamma(0.1)\n","random_seed (31, nX_read_flag (False)\n","Train (408), Validation (72), Test (120)\n","Epoch 1, lr(0.0001) : Avg loss(0.668605) : TP(29),FN(7),FP(1),TN(35) : Accuracy(0.88889), Precision(0.96667), Recall(0.80556), F1(0.87879) \n","Epoch 2, lr(0.0001) : Avg loss(0.605515) : TP(36),FN(0),FP(19),TN(17) : Accuracy(0.73611), Precision(0.65455), Recall(1.00000), F1(0.79121) \n","Epoch 3, lr(0.0001) : Avg loss(0.473646) : TP(36),FN(0),FP(3),TN(33) : Accuracy(0.95833), Precision(0.92308), Recall(1.00000), F1(0.96000) \n","Epoch 4, lr(0.0001) : Avg loss(0.392534) : TP(36),FN(0),FP(2),TN(34) : Accuracy(0.97222), Precision(0.94737), Recall(1.00000), F1(0.97297) \n","Epoch 5, lr(0.0001) : Avg loss(0.362056) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 6, lr(0.0001) : Avg loss(0.337750) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 7, lr(0.0001) : Avg loss(0.330987) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 8, lr(0.0001) : Avg loss(0.326328) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 9, lr(0.0001) : Avg loss(0.324095) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 10, lr(0.0001) : Avg loss(0.320811) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 11, lr(1e-05) : Avg loss(0.321387) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 12, lr(1e-05) : Avg loss(0.326433) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 13, lr(1e-05) : Avg loss(0.322289) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 14, lr(1e-05) : Avg loss(0.322814) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 15, lr(1e-05) : Avg loss(0.328897) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 16, lr(1e-05) : Avg loss(0.322098) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 17, lr(1e-05) : Avg loss(0.327500) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 18, lr(1e-05) : Avg loss(0.323713) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 19, lr(1e-05) : Avg loss(0.323136) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 20, lr(1e-05) : Avg loss(0.322406) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 21, lr(1.0000000000000002e-06) : Avg loss(0.322577) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 22, lr(1.0000000000000002e-06) : Avg loss(0.323290) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 23, lr(1.0000000000000002e-06) : Avg loss(0.327016) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 24, lr(1.0000000000000002e-06) : Avg loss(0.321871) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 25, lr(1.0000000000000002e-06) : Avg loss(0.321984) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 26, lr(1.0000000000000002e-06) : Avg loss(0.322714) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 27, lr(1.0000000000000002e-06) : Avg loss(0.321458) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 28, lr(1.0000000000000002e-06) : Avg loss(0.323002) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 29, lr(1.0000000000000002e-06) : Avg loss(0.323786) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 30, lr(1.0000000000000002e-06) : Avg loss(0.322941) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 31, lr(1.0000000000000002e-07) : Avg loss(0.323058) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 32, lr(1.0000000000000002e-07) : Avg loss(0.327761) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 33, lr(1.0000000000000002e-07) : Avg loss(0.321579) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 34, lr(1.0000000000000002e-07) : Avg loss(0.322541) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 35, lr(1.0000000000000002e-07) : Avg loss(0.322806) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 36, lr(1.0000000000000002e-07) : Avg loss(0.323436) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 37, lr(1.0000000000000002e-07) : Avg loss(0.327826) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 38, lr(1.0000000000000002e-07) : Avg loss(0.322781) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 39, lr(1.0000000000000002e-07) : Avg loss(0.322271) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 40, lr(1.0000000000000002e-07) : Avg loss(0.322868) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","==========================================\n","Training Time: 13.2440sec\n","Avg loss(0.319055) : TP(60),FN(0),FP(0),TN(60) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","*** Best model (epoch:40) : Avg loss(0.322461) : TP(60),FN(0),FP(0),TN(60) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Inference Time: 0.1622sec\n","saved model name : /home/dataset/log/SNU1_csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0_A_A_H5_P0_R31_0716064215\n","60, 0, 0, 60, SNU1_csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0_A_A_H5_P0_R31_0716064215\n","----------------------------------------------------\n","CNN (SNU1)\n","Loss function (CrossEntropy) opt (Adam, 0.0001) lr_scheduler (MultiStepLR), [10, 20, 30], gamma(0.1)\n","random_seed (31, nX_read_flag (False)\n","Train (408), Validation (72), Test (120)\n","Epoch 1, lr(0.0001) : Avg loss(0.680193) : TP(36),FN(0),FP(36),TN(0) : Accuracy(0.50000), Precision(0.50000), Recall(1.00000), F1(0.66667) \n","Epoch 2, lr(0.0001) : Avg loss(0.640129) : TP(36),FN(0),FP(31),TN(5) : Accuracy(0.56944), Precision(0.53731), Recall(1.00000), F1(0.69903) \n","Epoch 3, lr(0.0001) : Avg loss(0.534789) : TP(36),FN(0),FP(8),TN(28) : Accuracy(0.88889), Precision(0.81818), Recall(1.00000), F1(0.90000) \n","Epoch 4, lr(0.0001) : Avg loss(0.420113) : TP(36),FN(0),FP(2),TN(34) : Accuracy(0.97222), Precision(0.94737), Recall(1.00000), F1(0.97297) \n","Epoch 5, lr(0.0001) : Avg loss(0.351515) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 6, lr(0.0001) : Avg loss(0.330057) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 7, lr(0.0001) : Avg loss(0.326819) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 8, lr(0.0001) : Avg loss(0.324183) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 9, lr(0.0001) : Avg loss(0.327023) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 10, lr(0.0001) : Avg loss(0.328731) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 11, lr(1e-05) : Avg loss(0.322354) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 12, lr(1e-05) : Avg loss(0.328571) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 13, lr(1e-05) : Avg loss(0.322759) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 14, lr(1e-05) : Avg loss(0.322032) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 15, lr(1e-05) : Avg loss(0.321338) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 16, lr(1e-05) : Avg loss(0.322117) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 17, lr(1e-05) : Avg loss(0.321834) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 18, lr(1e-05) : Avg loss(0.327695) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 19, lr(1e-05) : Avg loss(0.327081) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 20, lr(1e-05) : Avg loss(0.322027) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 21, lr(1.0000000000000002e-06) : Avg loss(0.321208) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 22, lr(1.0000000000000002e-06) : Avg loss(0.327149) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 23, lr(1.0000000000000002e-06) : Avg loss(0.327193) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 24, lr(1.0000000000000002e-06) : Avg loss(0.322067) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 25, lr(1.0000000000000002e-06) : Avg loss(0.327545) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 26, lr(1.0000000000000002e-06) : Avg loss(0.321443) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 27, lr(1.0000000000000002e-06) : Avg loss(0.321352) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 28, lr(1.0000000000000002e-06) : Avg loss(0.327035) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 29, lr(1.0000000000000002e-06) : Avg loss(0.327277) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 30, lr(1.0000000000000002e-06) : Avg loss(0.321575) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 31, lr(1.0000000000000002e-07) : Avg loss(0.322026) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 32, lr(1.0000000000000002e-07) : Avg loss(0.321098) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 33, lr(1.0000000000000002e-07) : Avg loss(0.321152) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 34, lr(1.0000000000000002e-07) : Avg loss(0.321295) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 35, lr(1.0000000000000002e-07) : Avg loss(0.322196) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 36, lr(1.0000000000000002e-07) : Avg loss(0.321583) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 37, lr(1.0000000000000002e-07) : Avg loss(0.327132) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 38, lr(1.0000000000000002e-07) : Avg loss(0.321820) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 39, lr(1.0000000000000002e-07) : Avg loss(0.321277) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 40, lr(1.0000000000000002e-07) : Avg loss(0.321193) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","==========================================\n","Training Time: 13.1118sec\n","Avg loss(0.322508) : TP(60),FN(0),FP(0),TN(60) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","*** Best model (epoch:40) : Avg loss(0.319608) : TP(60),FN(0),FP(0),TN(60) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Inference Time: 0.1609sec\n","saved model name : /home/dataset/log/SNU1_csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0_A_A_H5_P0_R31_0716064229\n","60, 0, 0, 60, SNU1_csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0_A_A_H5_P0_R31_0716064229\n","----------------------------------------------------\n","Progress : [2/3]\n","\n","******* csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0_A_A, Train(['csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0/enva', '*/*/*.jpg']), Test (['', '']), epoch (40), bs (50), lr (0.0001), shuffle(True) \n","CNN (SNU1)\n","Loss function (CrossEntropy) opt (Adam, 0.0001) lr_scheduler (MultiStepLR), [10, 20, 30], gamma(0.1)\n","random_seed (42, nX_read_flag (False)\n","Train (408), Validation (72), Test (120)\n","Epoch 1, lr(0.0001) : Avg loss(0.674655) : TP(5),FN(31),FP(1),TN(35) : Accuracy(0.55556), Precision(0.83333), Recall(0.13889), F1(0.23810) \n","Epoch 2, lr(0.0001) : Avg loss(0.610212) : TP(35),FN(1),FP(2),TN(34) : Accuracy(0.95833), Precision(0.94595), Recall(0.97222), F1(0.95890) \n","Epoch 3, lr(0.0001) : Avg loss(0.534965) : TP(19),FN(17),FP(0),TN(36) : Accuracy(0.76389), Precision(1.00000), Recall(0.52778), F1(0.69091) \n","Epoch 4, lr(0.0001) : Avg loss(0.412022) : TP(35),FN(1),FP(1),TN(35) : Accuracy(0.97222), Precision(0.97222), Recall(0.97222), F1(0.97222) \n","Epoch 5, lr(0.0001) : Avg loss(0.354912) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 6, lr(0.0001) : Avg loss(0.347282) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 7, lr(0.0001) : Avg loss(0.339729) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 8, lr(0.0001) : Avg loss(0.334254) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 9, lr(0.0001) : Avg loss(0.326565) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 10, lr(0.0001) : Avg loss(0.325471) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 11, lr(1e-05) : Avg loss(0.324962) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 12, lr(1e-05) : Avg loss(0.323996) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 13, lr(1e-05) : Avg loss(0.325758) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 14, lr(1e-05) : Avg loss(0.325406) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 15, lr(1e-05) : Avg loss(0.331381) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 16, lr(1e-05) : Avg loss(0.330566) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 17, lr(1e-05) : Avg loss(0.329888) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 18, lr(1e-05) : Avg loss(0.324919) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 19, lr(1e-05) : Avg loss(0.329131) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 20, lr(1e-05) : Avg loss(0.324235) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 21, lr(1.0000000000000002e-06) : Avg loss(0.324134) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 22, lr(1.0000000000000002e-06) : Avg loss(0.329899) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 23, lr(1.0000000000000002e-06) : Avg loss(0.325243) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 24, lr(1.0000000000000002e-06) : Avg loss(0.324463) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 25, lr(1.0000000000000002e-06) : Avg loss(0.329145) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 26, lr(1.0000000000000002e-06) : Avg loss(0.325383) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 27, lr(1.0000000000000002e-06) : Avg loss(0.324123) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 28, lr(1.0000000000000002e-06) : Avg loss(0.324156) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 29, lr(1.0000000000000002e-06) : Avg loss(0.323839) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 30, lr(1.0000000000000002e-06) : Avg loss(0.329152) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 31, lr(1.0000000000000002e-07) : Avg loss(0.323461) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 32, lr(1.0000000000000002e-07) : Avg loss(0.325044) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 33, lr(1.0000000000000002e-07) : Avg loss(0.329853) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 34, lr(1.0000000000000002e-07) : Avg loss(0.330110) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 35, lr(1.0000000000000002e-07) : Avg loss(0.324569) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 36, lr(1.0000000000000002e-07) : Avg loss(0.329925) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 37, lr(1.0000000000000002e-07) : Avg loss(0.324686) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 38, lr(1.0000000000000002e-07) : Avg loss(0.330774) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 39, lr(1.0000000000000002e-07) : Avg loss(0.324885) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 40, lr(1.0000000000000002e-07) : Avg loss(0.329011) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","==========================================\n","Training Time: 13.2338sec\n","Avg loss(0.328935) : TP(60),FN(0),FP(0),TN(60) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","*** Best model (epoch:31) : Avg loss(0.326169) : TP(60),FN(0),FP(0),TN(60) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Inference Time: 0.1649sec\n","saved model name : /home/dataset/log/SNU1_csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0_A_A_H5_P0_R42_0716064242\n","60, 0, 0, 60, SNU1_csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0_A_A_H5_P0_R42_0716064242\n","----------------------------------------------------\n","CNN (SNU1)\n","Loss function (CrossEntropy) opt (Adam, 0.0001) lr_scheduler (MultiStepLR), [10, 20, 30], gamma(0.1)\n","random_seed (42, nX_read_flag (False)\n","Train (408), Validation (72), Test (120)\n","Epoch 1, lr(0.0001) : Avg loss(0.687315) : TP(0),FN(36),FP(0),TN(36) : Accuracy(0.50000), Precision(nan), Recall(0.00000), F1(nan) \n","Epoch 2, lr(0.0001) : Avg loss(0.683522) : TP(0),FN(36),FP(0),TN(36) : Accuracy(0.50000), Precision(nan), Recall(0.00000), F1(nan) \n","Epoch 3, lr(0.0001) : Avg loss(0.706048) : TP(0),FN(36),FP(0),TN(36) : Accuracy(0.50000), Precision(nan), Recall(0.00000), F1(nan) \n","Epoch 4, lr(0.0001) : Avg loss(0.474542) : TP(26),FN(10),FP(0),TN(36) : Accuracy(0.86111), Precision(1.00000), Recall(0.72222), F1(0.83871) \n","Epoch 5, lr(0.0001) : Avg loss(0.401338) : TP(33),FN(3),FP(0),TN(36) : Accuracy(0.95833), Precision(1.00000), Recall(0.91667), F1(0.95652) \n","Epoch 6, lr(0.0001) : Avg loss(0.343029) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 7, lr(0.0001) : Avg loss(0.332749) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 8, lr(0.0001) : Avg loss(0.333934) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 9, lr(0.0001) : Avg loss(0.325270) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 10, lr(0.0001) : Avg loss(0.333339) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 11, lr(1e-05) : Avg loss(0.325937) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 12, lr(1e-05) : Avg loss(0.324979) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 13, lr(1e-05) : Avg loss(0.332497) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 14, lr(1e-05) : Avg loss(0.324984) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 15, lr(1e-05) : Avg loss(0.323844) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 16, lr(1e-05) : Avg loss(0.323492) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 17, lr(1e-05) : Avg loss(0.324024) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 18, lr(1e-05) : Avg loss(0.332516) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 19, lr(1e-05) : Avg loss(0.332203) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 20, lr(1e-05) : Avg loss(0.323907) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 21, lr(1.0000000000000002e-06) : Avg loss(0.323930) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 22, lr(1.0000000000000002e-06) : Avg loss(0.324572) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 23, lr(1.0000000000000002e-06) : Avg loss(0.324845) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 24, lr(1.0000000000000002e-06) : Avg loss(0.324833) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 25, lr(1.0000000000000002e-06) : Avg loss(0.324156) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 26, lr(1.0000000000000002e-06) : Avg loss(0.323972) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 27, lr(1.0000000000000002e-06) : Avg loss(0.332813) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 28, lr(1.0000000000000002e-06) : Avg loss(0.332135) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 29, lr(1.0000000000000002e-06) : Avg loss(0.332698) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 30, lr(1.0000000000000002e-06) : Avg loss(0.325311) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 31, lr(1.0000000000000002e-07) : Avg loss(0.325072) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 32, lr(1.0000000000000002e-07) : Avg loss(0.325509) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 33, lr(1.0000000000000002e-07) : Avg loss(0.331880) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 34, lr(1.0000000000000002e-07) : Avg loss(0.323474) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 35, lr(1.0000000000000002e-07) : Avg loss(0.324644) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 36, lr(1.0000000000000002e-07) : Avg loss(0.324504) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 37, lr(1.0000000000000002e-07) : Avg loss(0.331182) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 38, lr(1.0000000000000002e-07) : Avg loss(0.331247) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 39, lr(1.0000000000000002e-07) : Avg loss(0.332831) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","Epoch 40, lr(1.0000000000000002e-07) : Avg loss(0.331091) : TP(36),FN(0),FP(1),TN(35) : Accuracy(0.98611), Precision(0.97297), Recall(1.00000), F1(0.98630) \n","==========================================\n","Training Time: 13.3612sec\n","Avg loss(0.334717) : TP(59),FN(1),FP(2),TN(58) : Accuracy(0.97500), Precision(0.96721), Recall(0.98333), F1(0.97521) \n","*** Best model (epoch:34) : Avg loss(0.331277) : TP(59),FN(1),FP(2),TN(58) : Accuracy(0.97500), Precision(0.96721), Recall(0.98333), F1(0.97521) \n","Inference Time: 0.1642sec\n","saved model name : /home/dataset/log/SNU1_csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0_A_A_H5_P0_R42_0716064256\n","59, 1, 2, 58, SNU1_csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0_A_A_H5_P0_R42_0716064256\n","----------------------------------------------------\n","Progress : [3/3]\n","\n","******* csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0_A_A, Train(['csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0/enva', '*/*/*.jpg']), Test (['', '']), epoch (40), bs (50), lr (0.0001), shuffle(True) \n","CNN (SNU1)\n","Loss function (CrossEntropy) opt (Adam, 0.0001) lr_scheduler (MultiStepLR), [10, 20, 30], gamma(0.1)\n","random_seed (5, nX_read_flag (False)\n","Train (408), Validation (72), Test (120)\n","Epoch 1, lr(0.0001) : Avg loss(0.684015) : TP(36),FN(0),FP(36),TN(0) : Accuracy(0.50000), Precision(0.50000), Recall(1.00000), F1(0.66667) \n","Epoch 2, lr(0.0001) : Avg loss(0.615867) : TP(36),FN(0),FP(23),TN(13) : Accuracy(0.68056), Precision(0.61017), Recall(1.00000), F1(0.75789) \n","Epoch 3, lr(0.0001) : Avg loss(0.567144) : TP(36),FN(0),FP(22),TN(14) : Accuracy(0.69444), Precision(0.62069), Recall(1.00000), F1(0.76596) \n","Epoch 4, lr(0.0001) : Avg loss(0.443080) : TP(36),FN(0),FP(9),TN(27) : Accuracy(0.87500), Precision(0.80000), Recall(1.00000), F1(0.88889) \n","Epoch 5, lr(0.0001) : Avg loss(0.353156) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 6, lr(0.0001) : Avg loss(0.331596) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 7, lr(0.0001) : Avg loss(0.326218) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 8, lr(0.0001) : Avg loss(0.326250) : TP(35),FN(1),FP(0),TN(36) : Accuracy(0.98611), Precision(1.00000), Recall(0.97222), F1(0.98592) \n","Epoch 9, lr(0.0001) : Avg loss(0.323304) : TP(35),FN(1),FP(0),TN(36) : Accuracy(0.98611), Precision(1.00000), Recall(0.97222), F1(0.98592) \n","Epoch 10, lr(0.0001) : Avg loss(0.320297) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 11, lr(1e-05) : Avg loss(0.321981) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 12, lr(1e-05) : Avg loss(0.320129) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 13, lr(1e-05) : Avg loss(0.319857) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 14, lr(1e-05) : Avg loss(0.324287) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 15, lr(1e-05) : Avg loss(0.319552) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 16, lr(1e-05) : Avg loss(0.324434) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 17, lr(1e-05) : Avg loss(0.320847) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 18, lr(1e-05) : Avg loss(0.319740) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 19, lr(1e-05) : Avg loss(0.319372) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 20, lr(1e-05) : Avg loss(0.323373) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 21, lr(1.0000000000000002e-06) : Avg loss(0.319358) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 22, lr(1.0000000000000002e-06) : Avg loss(0.319711) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 23, lr(1.0000000000000002e-06) : Avg loss(0.319785) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 24, lr(1.0000000000000002e-06) : Avg loss(0.323156) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 25, lr(1.0000000000000002e-06) : Avg loss(0.320356) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 26, lr(1.0000000000000002e-06) : Avg loss(0.323361) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 27, lr(1.0000000000000002e-06) : Avg loss(0.323856) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 28, lr(1.0000000000000002e-06) : Avg loss(0.320100) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 29, lr(1.0000000000000002e-06) : Avg loss(0.320106) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 30, lr(1.0000000000000002e-06) : Avg loss(0.323947) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 31, lr(1.0000000000000002e-07) : Avg loss(0.320026) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 32, lr(1.0000000000000002e-07) : Avg loss(0.322653) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 33, lr(1.0000000000000002e-07) : Avg loss(0.322998) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 34, lr(1.0000000000000002e-07) : Avg loss(0.322837) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 35, lr(1.0000000000000002e-07) : Avg loss(0.319964) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 36, lr(1.0000000000000002e-07) : Avg loss(0.319025) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 37, lr(1.0000000000000002e-07) : Avg loss(0.324121) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 38, lr(1.0000000000000002e-07) : Avg loss(0.318933) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 39, lr(1.0000000000000002e-07) : Avg loss(0.320279) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 40, lr(1.0000000000000002e-07) : Avg loss(0.322820) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","==========================================\n","Training Time: 13.4737sec\n","Avg loss(0.330117) : TP(60),FN(0),FP(2),TN(58) : Accuracy(0.98333), Precision(0.96774), Recall(1.00000), F1(0.98361) \n","*** Best model (epoch:38) : Avg loss(0.332543) : TP(60),FN(0),FP(2),TN(58) : Accuracy(0.98333), Precision(0.96774), Recall(1.00000), F1(0.98361) \n","Inference Time: 0.1825sec\n","saved model name : /home/dataset/log/SNU1_csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0_A_A_H5_P0_R5_0716064310\n","60, 0, 2, 58, SNU1_csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0_A_A_H5_P0_R5_0716064310\n","----------------------------------------------------\n","CNN (SNU1)\n","Loss function (CrossEntropy) opt (Adam, 0.0001) lr_scheduler (MultiStepLR), [10, 20, 30], gamma(0.1)\n","random_seed (5, nX_read_flag (False)\n","Train (408), Validation (72), Test (120)\n","Epoch 1, lr(0.0001) : Avg loss(0.689587) : TP(36),FN(0),FP(36),TN(0) : Accuracy(0.50000), Precision(0.50000), Recall(1.00000), F1(0.66667) \n","Epoch 2, lr(0.0001) : Avg loss(0.659184) : TP(36),FN(0),FP(34),TN(2) : Accuracy(0.52778), Precision(0.51429), Recall(1.00000), F1(0.67925) \n","Epoch 3, lr(0.0001) : Avg loss(0.545229) : TP(36),FN(0),FP(4),TN(32) : Accuracy(0.94444), Precision(0.90000), Recall(1.00000), F1(0.94737) \n","Epoch 4, lr(0.0001) : Avg loss(0.404550) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 5, lr(0.0001) : Avg loss(0.356312) : TP(36),FN(0),FP(2),TN(34) : Accuracy(0.97222), Precision(0.94737), Recall(1.00000), F1(0.97297) \n","Epoch 6, lr(0.0001) : Avg loss(0.325419) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 7, lr(0.0001) : Avg loss(0.318914) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 8, lr(0.0001) : Avg loss(0.318803) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 9, lr(0.0001) : Avg loss(0.317058) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 10, lr(0.0001) : Avg loss(0.317635) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 11, lr(1e-05) : Avg loss(0.316812) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 12, lr(1e-05) : Avg loss(0.317326) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 13, lr(1e-05) : Avg loss(0.316463) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 14, lr(1e-05) : Avg loss(0.317937) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 15, lr(1e-05) : Avg loss(0.316244) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 16, lr(1e-05) : Avg loss(0.317835) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 17, lr(1e-05) : Avg loss(0.316586) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 18, lr(1e-05) : Avg loss(0.317332) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 19, lr(1e-05) : Avg loss(0.316272) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 20, lr(1e-05) : Avg loss(0.316934) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 21, lr(1.0000000000000002e-06) : Avg loss(0.317304) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 22, lr(1.0000000000000002e-06) : Avg loss(0.317950) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 23, lr(1.0000000000000002e-06) : Avg loss(0.316577) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 24, lr(1.0000000000000002e-06) : Avg loss(0.316338) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 25, lr(1.0000000000000002e-06) : Avg loss(0.316517) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 26, lr(1.0000000000000002e-06) : Avg loss(0.316095) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 27, lr(1.0000000000000002e-06) : Avg loss(0.316285) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 28, lr(1.0000000000000002e-06) : Avg loss(0.316329) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 29, lr(1.0000000000000002e-06) : Avg loss(0.316318) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 30, lr(1.0000000000000002e-06) : Avg loss(0.316525) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 31, lr(1.0000000000000002e-07) : Avg loss(0.317199) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 32, lr(1.0000000000000002e-07) : Avg loss(0.316608) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 33, lr(1.0000000000000002e-07) : Avg loss(0.316365) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 34, lr(1.0000000000000002e-07) : Avg loss(0.316305) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 35, lr(1.0000000000000002e-07) : Avg loss(0.316365) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 36, lr(1.0000000000000002e-07) : Avg loss(0.316186) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 37, lr(1.0000000000000002e-07) : Avg loss(0.317766) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 38, lr(1.0000000000000002e-07) : Avg loss(0.316262) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 39, lr(1.0000000000000002e-07) : Avg loss(0.316896) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 40, lr(1.0000000000000002e-07) : Avg loss(0.317135) : TP(36),FN(0),FP(0),TN(36) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","==========================================\n","Training Time: 13.5196sec\n","Avg loss(0.325772) : TP(60),FN(0),FP(3),TN(57) : Accuracy(0.97500), Precision(0.95238), Recall(1.00000), F1(0.97561) \n","*** Best model (epoch:26) : Avg loss(0.326232) : TP(60),FN(0),FP(3),TN(57) : Accuracy(0.97500), Precision(0.95238), Recall(1.00000), F1(0.97561) \n","Inference Time: 0.1611sec\n","saved model name : /home/dataset/log/SNU1_csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0_A_A_H5_P0_R5_0716064324\n","60, 0, 3, 57, SNU1_csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0_A_A_H5_P0_R5_0716064324\n","----------------------------------------------------\n","60\t0\t0\t60\tSNU1_csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0_A_A_H5_P0_R31_0716064215\n","60\t0\t0\t60\tSNU1_csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0_A_A_H5_P0_R31_0716064229\n","60\t0\t0\t60\tSNU1_csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0_A_A_H5_P0_R42_0716064242\n","59\t1\t2\t58\tSNU1_csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0_A_A_H5_P0_R42_0716064256\n","60\t0\t2\t58\tSNU1_csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0_A_A_H5_P0_R5_0716064310\n","60\t0\t3\t57\tSNU1_csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0_A_A_H5_P0_R5_0716064324\n","\n","Processed on cuda...\n","Progress : [1/3]\n","\n","******* csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0_B_A, Train(['csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0/envb', '*/*/*.jpg']), Test (['csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0/enva', '*/*/*.jpg']), epoch (40), bs (50), lr (0.0001), shuffle(True) \n","CNN (R18)\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","100%|██████████| 44.7M/44.7M [00:00<00:00, 232MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Loss function (CrossEntropy) opt (Adam, 0.0001) lr_scheduler (MultiStepLR), [10, 20, 30], gamma(0.1)\n","random_seed (31, nX_read_flag (False)\n","Train (306), Validation (54), Test (600)\n","Epoch 1, lr(0.0001) : Avg loss(0.244607) : TP(16),FN(11),FP(1),TN(26) : Accuracy(0.77778), Precision(0.94118), Recall(0.59259), F1(0.72727) \n","Epoch 2, lr(0.0001) : Avg loss(0.159502) : TP(24),FN(3),FP(1),TN(26) : Accuracy(0.92593), Precision(0.96000), Recall(0.88889), F1(0.92308) \n","Epoch 3, lr(0.0001) : Avg loss(0.280638) : TP(24),FN(3),FP(2),TN(25) : Accuracy(0.90741), Precision(0.92308), Recall(0.88889), F1(0.90566) \n","Epoch 4, lr(0.0001) : Avg loss(1.014641) : TP(24),FN(3),FP(2),TN(25) : Accuracy(0.90741), Precision(0.92308), Recall(0.88889), F1(0.90566) \n","Epoch 5, lr(0.0001) : Avg loss(0.384274) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 6, lr(0.0001) : Avg loss(0.495111) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 7, lr(0.0001) : Avg loss(0.900709) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 8, lr(0.0001) : Avg loss(0.155289) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 9, lr(0.0001) : Avg loss(0.155367) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 10, lr(0.0001) : Avg loss(0.170379) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 11, lr(1e-05) : Avg loss(0.540919) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 12, lr(1e-05) : Avg loss(0.153396) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 13, lr(1e-05) : Avg loss(0.148818) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 14, lr(1e-05) : Avg loss(0.192512) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 15, lr(1e-05) : Avg loss(0.150958) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 16, lr(1e-05) : Avg loss(0.154187) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 17, lr(1e-05) : Avg loss(0.202846) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 18, lr(1e-05) : Avg loss(0.460772) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 19, lr(1e-05) : Avg loss(0.152958) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 20, lr(1e-05) : Avg loss(0.153192) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 21, lr(1.0000000000000002e-06) : Avg loss(0.153023) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 22, lr(1.0000000000000002e-06) : Avg loss(0.375060) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 23, lr(1.0000000000000002e-06) : Avg loss(0.151082) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 24, lr(1.0000000000000002e-06) : Avg loss(1.274327) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 25, lr(1.0000000000000002e-06) : Avg loss(0.150486) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 26, lr(1.0000000000000002e-06) : Avg loss(0.349401) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 27, lr(1.0000000000000002e-06) : Avg loss(0.416431) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 28, lr(1.0000000000000002e-06) : Avg loss(0.149611) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 29, lr(1.0000000000000002e-06) : Avg loss(0.664245) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 30, lr(1.0000000000000002e-06) : Avg loss(0.150590) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 31, lr(1.0000000000000002e-07) : Avg loss(0.155545) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 32, lr(1.0000000000000002e-07) : Avg loss(0.566591) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 33, lr(1.0000000000000002e-07) : Avg loss(0.203022) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 34, lr(1.0000000000000002e-07) : Avg loss(0.154575) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 35, lr(1.0000000000000002e-07) : Avg loss(0.150579) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 36, lr(1.0000000000000002e-07) : Avg loss(0.157044) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 37, lr(1.0000000000000002e-07) : Avg loss(0.154575) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 38, lr(1.0000000000000002e-07) : Avg loss(0.699975) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 39, lr(1.0000000000000002e-07) : Avg loss(1.261050) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 40, lr(1.0000000000000002e-07) : Avg loss(0.348024) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","==========================================\n","Training Time: 46.6308sec\n","Avg loss(0.082970) : TP(290),FN(10),FP(12),TN(288) : Accuracy(0.96333), Precision(0.96026), Recall(0.96667), F1(0.96346) \n","*** Best model (epoch:40) : Avg loss(0.082970) : TP(290),FN(10),FP(12),TN(288) : Accuracy(0.96333), Precision(0.96026), Recall(0.96667), F1(0.96346) \n","Inference Time: 2.4138sec\n","saved model name : /home/dataset/log/R18_csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0_B_A_H5_P0_R31_0716064414\n","290, 10, 12, 288, R18_csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0_B_A_H5_P0_R31_0716064414\n","----------------------------------------------------\n","CNN (R18)\n","Loss function (CrossEntropy) opt (Adam, 0.0001) lr_scheduler (MultiStepLR), [10, 20, 30], gamma(0.1)\n","random_seed (31, nX_read_flag (False)\n","Train (306), Validation (54), Test (600)\n","Epoch 1, lr(0.0001) : Avg loss(0.244650) : TP(19),FN(8),FP(0),TN(27) : Accuracy(0.85185), Precision(1.00000), Recall(0.70370), F1(0.82609) \n","Epoch 2, lr(0.0001) : Avg loss(0.251467) : TP(24),FN(3),FP(2),TN(25) : Accuracy(0.90741), Precision(0.92308), Recall(0.88889), F1(0.90566) \n","Epoch 3, lr(0.0001) : Avg loss(0.937563) : TP(24),FN(3),FP(2),TN(25) : Accuracy(0.90741), Precision(0.92308), Recall(0.88889), F1(0.90566) \n","Epoch 4, lr(0.0001) : Avg loss(0.172644) : TP(24),FN(3),FP(3),TN(24) : Accuracy(0.88889), Precision(0.88889), Recall(0.88889), F1(0.88889) \n","Epoch 5, lr(0.0001) : Avg loss(0.430656) : TP(24),FN(3),FP(4),TN(23) : Accuracy(0.87037), Precision(0.85714), Recall(0.88889), F1(0.87273) \n","Epoch 6, lr(0.0001) : Avg loss(0.178630) : TP(26),FN(1),FP(4),TN(23) : Accuracy(0.90741), Precision(0.86667), Recall(0.96296), F1(0.91228) \n","Epoch 7, lr(0.0001) : Avg loss(0.101360) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 8, lr(0.0001) : Avg loss(0.136758) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 9, lr(0.0001) : Avg loss(0.112724) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 10, lr(0.0001) : Avg loss(0.181644) : TP(26),FN(1),FP(2),TN(25) : Accuracy(0.94444), Precision(0.92857), Recall(0.96296), F1(0.94545) \n","Epoch 11, lr(1e-05) : Avg loss(0.109515) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 12, lr(1e-05) : Avg loss(0.091785) : TP(26),FN(1),FP(2),TN(25) : Accuracy(0.94444), Precision(0.92857), Recall(0.96296), F1(0.94545) \n","Epoch 13, lr(1e-05) : Avg loss(0.097934) : TP(26),FN(1),FP(2),TN(25) : Accuracy(0.94444), Precision(0.92857), Recall(0.96296), F1(0.94545) \n","Epoch 14, lr(1e-05) : Avg loss(0.131633) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 15, lr(1e-05) : Avg loss(0.095444) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 16, lr(1e-05) : Avg loss(0.127670) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 17, lr(1e-05) : Avg loss(0.312722) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 18, lr(1e-05) : Avg loss(0.537174) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 19, lr(1e-05) : Avg loss(0.236210) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 20, lr(1e-05) : Avg loss(0.103134) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 21, lr(1.0000000000000002e-06) : Avg loss(0.100868) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 22, lr(1.0000000000000002e-06) : Avg loss(0.101060) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 23, lr(1.0000000000000002e-06) : Avg loss(0.106103) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 24, lr(1.0000000000000002e-06) : Avg loss(0.101172) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 25, lr(1.0000000000000002e-06) : Avg loss(0.105031) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 26, lr(1.0000000000000002e-06) : Avg loss(0.436677) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 27, lr(1.0000000000000002e-06) : Avg loss(0.098234) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 28, lr(1.0000000000000002e-06) : Avg loss(0.099838) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 29, lr(1.0000000000000002e-06) : Avg loss(0.095461) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 30, lr(1.0000000000000002e-06) : Avg loss(0.102321) : TP(26),FN(1),FP(2),TN(25) : Accuracy(0.94444), Precision(0.92857), Recall(0.96296), F1(0.94545) \n","Epoch 31, lr(1.0000000000000002e-07) : Avg loss(0.098804) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 32, lr(1.0000000000000002e-07) : Avg loss(0.115863) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 33, lr(1.0000000000000002e-07) : Avg loss(0.100733) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 34, lr(1.0000000000000002e-07) : Avg loss(0.099966) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 35, lr(1.0000000000000002e-07) : Avg loss(0.105099) : TP(24),FN(3),FP(2),TN(25) : Accuracy(0.90741), Precision(0.92308), Recall(0.88889), F1(0.90566) \n","Epoch 36, lr(1.0000000000000002e-07) : Avg loss(0.112837) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 37, lr(1.0000000000000002e-07) : Avg loss(0.101978) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 38, lr(1.0000000000000002e-07) : Avg loss(0.120192) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 39, lr(1.0000000000000002e-07) : Avg loss(0.100695) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","Epoch 40, lr(1.0000000000000002e-07) : Avg loss(0.100002) : TP(25),FN(2),FP(2),TN(25) : Accuracy(0.92593), Precision(0.92593), Recall(0.92593), F1(0.92593) \n","==========================================\n","Training Time: 46.0210sec\n","Avg loss(0.118781) : TP(290),FN(10),FP(16),TN(284) : Accuracy(0.95667), Precision(0.94771), Recall(0.96667), F1(0.95710) \n","*** Best model (epoch:12) : Avg loss(0.118781) : TP(290),FN(10),FP(16),TN(284) : Accuracy(0.95667), Precision(0.94771), Recall(0.96667), F1(0.95710) \n","Inference Time: 2.4569sec\n","saved model name : /home/dataset/log/R18_csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0_B_A_H5_P0_R31_0716064503\n","290, 10, 16, 284, R18_csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0_B_A_H5_P0_R31_0716064503\n","----------------------------------------------------\n","Progress : [2/3]\n","\n","******* csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0_B_A, Train(['csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0/envb', '*/*/*.jpg']), Test (['csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0/enva', '*/*/*.jpg']), epoch (40), bs (50), lr (0.0001), shuffle(True) \n","CNN (R18)\n","Loss function (CrossEntropy) opt (Adam, 0.0001) lr_scheduler (MultiStepLR), [10, 20, 30], gamma(0.1)\n","random_seed (42, nX_read_flag (False)\n","Train (306), Validation (54), Test (600)\n","Epoch 1, lr(0.0001) : Avg loss(0.148829) : TP(24),FN(3),FP(1),TN(26) : Accuracy(0.92593), Precision(0.96000), Recall(0.88889), F1(0.92308) \n","Epoch 2, lr(0.0001) : Avg loss(0.180984) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 3, lr(0.0001) : Avg loss(0.081078) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 4, lr(0.0001) : Avg loss(0.097351) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 5, lr(0.0001) : Avg loss(0.106119) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 6, lr(0.0001) : Avg loss(0.096127) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 7, lr(0.0001) : Avg loss(0.079710) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 8, lr(0.0001) : Avg loss(0.083302) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 9, lr(0.0001) : Avg loss(0.072211) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 10, lr(0.0001) : Avg loss(0.980275) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 11, lr(1e-05) : Avg loss(0.091938) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 12, lr(1e-05) : Avg loss(0.081228) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 13, lr(1e-05) : Avg loss(0.095345) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 14, lr(1e-05) : Avg loss(0.121996) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 15, lr(1e-05) : Avg loss(0.665349) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 16, lr(1e-05) : Avg loss(0.746898) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 17, lr(1e-05) : Avg loss(0.090711) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 18, lr(1e-05) : Avg loss(0.079126) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 19, lr(1e-05) : Avg loss(0.620614) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 20, lr(1e-05) : Avg loss(0.068380) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 21, lr(1.0000000000000002e-06) : Avg loss(0.067696) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 22, lr(1.0000000000000002e-06) : Avg loss(0.062117) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 23, lr(1.0000000000000002e-06) : Avg loss(0.074187) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 24, lr(1.0000000000000002e-06) : Avg loss(0.068978) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 25, lr(1.0000000000000002e-06) : Avg loss(0.064033) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 26, lr(1.0000000000000002e-06) : Avg loss(0.081044) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 27, lr(1.0000000000000002e-06) : Avg loss(0.101663) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 28, lr(1.0000000000000002e-06) : Avg loss(0.087248) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 29, lr(1.0000000000000002e-06) : Avg loss(0.124069) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 30, lr(1.0000000000000002e-06) : Avg loss(0.079741) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 31, lr(1.0000000000000002e-07) : Avg loss(0.067098) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 32, lr(1.0000000000000002e-07) : Avg loss(0.077103) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 33, lr(1.0000000000000002e-07) : Avg loss(0.069903) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 34, lr(1.0000000000000002e-07) : Avg loss(0.075949) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 35, lr(1.0000000000000002e-07) : Avg loss(0.067863) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 36, lr(1.0000000000000002e-07) : Avg loss(0.071110) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 37, lr(1.0000000000000002e-07) : Avg loss(0.088542) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 38, lr(1.0000000000000002e-07) : Avg loss(0.072865) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 39, lr(1.0000000000000002e-07) : Avg loss(0.070792) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 40, lr(1.0000000000000002e-07) : Avg loss(0.068497) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","==========================================\n","Training Time: 46.1966sec\n","Avg loss(0.191738) : TP(297),FN(3),FP(47),TN(253) : Accuracy(0.91667), Precision(0.86337), Recall(0.99000), F1(0.92236) \n","*** Best model (epoch:22) : Avg loss(0.191738) : TP(297),FN(3),FP(47),TN(253) : Accuracy(0.91667), Precision(0.86337), Recall(0.99000), F1(0.92236) \n","Inference Time: 2.3378sec\n","saved model name : /home/dataset/log/R18_csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0_B_A_H5_P0_R42_0716064553\n","297, 3, 47, 253, R18_csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0_B_A_H5_P0_R42_0716064553\n","----------------------------------------------------\n","CNN (R18)\n","Loss function (CrossEntropy) opt (Adam, 0.0001) lr_scheduler (MultiStepLR), [10, 20, 30], gamma(0.1)\n","random_seed (42, nX_read_flag (False)\n","Train (306), Validation (54), Test (600)\n","Epoch 1, lr(0.0001) : Avg loss(0.233484) : TP(26),FN(1),FP(2),TN(25) : Accuracy(0.94444), Precision(0.92857), Recall(0.96296), F1(0.94545) \n","Epoch 2, lr(0.0001) : Avg loss(0.072031) : TP(27),FN(0),FP(3),TN(24) : Accuracy(0.94444), Precision(0.90000), Recall(1.00000), F1(0.94737) \n","Epoch 3, lr(0.0001) : Avg loss(0.072312) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 4, lr(0.0001) : Avg loss(0.078600) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 5, lr(0.0001) : Avg loss(0.428686) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 6, lr(0.0001) : Avg loss(0.088029) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 7, lr(0.0001) : Avg loss(0.375730) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 8, lr(0.0001) : Avg loss(0.078754) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 9, lr(0.0001) : Avg loss(0.078788) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 10, lr(0.0001) : Avg loss(0.091178) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 11, lr(1e-05) : Avg loss(0.083038) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 12, lr(1e-05) : Avg loss(0.086715) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 13, lr(1e-05) : Avg loss(0.092695) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 14, lr(1e-05) : Avg loss(0.798793) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 15, lr(1e-05) : Avg loss(0.076269) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 16, lr(1e-05) : Avg loss(0.078919) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 17, lr(1e-05) : Avg loss(0.082374) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 18, lr(1e-05) : Avg loss(0.083164) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 19, lr(1e-05) : Avg loss(0.078008) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 20, lr(1e-05) : Avg loss(0.353386) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 21, lr(1.0000000000000002e-06) : Avg loss(0.112808) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 22, lr(1.0000000000000002e-06) : Avg loss(0.110894) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 23, lr(1.0000000000000002e-06) : Avg loss(0.097684) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 24, lr(1.0000000000000002e-06) : Avg loss(0.097777) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 25, lr(1.0000000000000002e-06) : Avg loss(0.083116) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 26, lr(1.0000000000000002e-06) : Avg loss(0.327786) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 27, lr(1.0000000000000002e-06) : Avg loss(0.087374) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 28, lr(1.0000000000000002e-06) : Avg loss(0.091911) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 29, lr(1.0000000000000002e-06) : Avg loss(0.104549) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 30, lr(1.0000000000000002e-06) : Avg loss(0.101857) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 31, lr(1.0000000000000002e-07) : Avg loss(0.097713) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 32, lr(1.0000000000000002e-07) : Avg loss(1.004994) : TP(27),FN(0),FP(3),TN(24) : Accuracy(0.94444), Precision(0.90000), Recall(1.00000), F1(0.94737) \n","Epoch 33, lr(1.0000000000000002e-07) : Avg loss(0.112328) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 34, lr(1.0000000000000002e-07) : Avg loss(0.115025) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 35, lr(1.0000000000000002e-07) : Avg loss(0.315739) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 36, lr(1.0000000000000002e-07) : Avg loss(0.094739) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 37, lr(1.0000000000000002e-07) : Avg loss(0.079925) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 38, lr(1.0000000000000002e-07) : Avg loss(0.107372) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 39, lr(1.0000000000000002e-07) : Avg loss(0.168325) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 40, lr(1.0000000000000002e-07) : Avg loss(0.451918) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","==========================================\n","Training Time: 46.1857sec\n","Avg loss(0.253988) : TP(300),FN(0),FP(65),TN(235) : Accuracy(0.89167), Precision(0.82192), Recall(1.00000), F1(0.90226) \n","*** Best model (epoch:2) : Avg loss(0.253988) : TP(300),FN(0),FP(65),TN(235) : Accuracy(0.89167), Precision(0.82192), Recall(1.00000), F1(0.90226) \n","Inference Time: 2.3621sec\n","saved model name : /home/dataset/log/R18_csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0_B_A_H5_P0_R42_0716064642\n","300, 0, 65, 235, R18_csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0_B_A_H5_P0_R42_0716064642\n","----------------------------------------------------\n","Progress : [3/3]\n","\n","******* csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0_B_A, Train(['csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0/envb', '*/*/*.jpg']), Test (['csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0/enva', '*/*/*.jpg']), epoch (40), bs (50), lr (0.0001), shuffle(True) \n","CNN (R18)\n","Loss function (CrossEntropy) opt (Adam, 0.0001) lr_scheduler (MultiStepLR), [10, 20, 30], gamma(0.1)\n","random_seed (5, nX_read_flag (False)\n","Train (306), Validation (54), Test (600)\n","Epoch 1, lr(0.0001) : Avg loss(0.128875) : TP(21),FN(6),FP(0),TN(27) : Accuracy(0.88889), Precision(1.00000), Recall(0.77778), F1(0.87500) \n","Epoch 2, lr(0.0001) : Avg loss(0.048686) : TP(26),FN(1),FP(1),TN(26) : Accuracy(0.96296), Precision(0.96296), Recall(0.96296), F1(0.96296) \n","Epoch 3, lr(0.0001) : Avg loss(0.026407) : TP(27),FN(0),FP(1),TN(26) : Accuracy(0.98148), Precision(0.96429), Recall(1.00000), F1(0.98182) \n","Epoch 4, lr(0.0001) : Avg loss(0.100133) : TP(27),FN(0),FP(1),TN(26) : Accuracy(0.98148), Precision(0.96429), Recall(1.00000), F1(0.98182) \n","Epoch 5, lr(0.0001) : Avg loss(0.023736) : TP(27),FN(0),FP(1),TN(26) : Accuracy(0.98148), Precision(0.96429), Recall(1.00000), F1(0.98182) \n","Epoch 6, lr(0.0001) : Avg loss(0.025300) : TP(27),FN(0),FP(1),TN(26) : Accuracy(0.98148), Precision(0.96429), Recall(1.00000), F1(0.98182) \n","Epoch 7, lr(0.0001) : Avg loss(0.023408) : TP(27),FN(0),FP(1),TN(26) : Accuracy(0.98148), Precision(0.96429), Recall(1.00000), F1(0.98182) \n","Epoch 8, lr(0.0001) : Avg loss(0.024208) : TP(27),FN(0),FP(1),TN(26) : Accuracy(0.98148), Precision(0.96429), Recall(1.00000), F1(0.98182) \n","Epoch 9, lr(0.0001) : Avg loss(0.027674) : TP(27),FN(0),FP(1),TN(26) : Accuracy(0.98148), Precision(0.96429), Recall(1.00000), F1(0.98182) \n","Epoch 10, lr(0.0001) : Avg loss(0.024814) : TP(27),FN(0),FP(1),TN(26) : Accuracy(0.98148), Precision(0.96429), Recall(1.00000), F1(0.98182) \n","Epoch 11, lr(1e-05) : Avg loss(0.254173) : TP(27),FN(0),FP(1),TN(26) : Accuracy(0.98148), Precision(0.96429), Recall(1.00000), F1(0.98182) \n","Epoch 12, lr(1e-05) : Avg loss(0.038545) : TP(27),FN(0),FP(1),TN(26) : Accuracy(0.98148), Precision(0.96429), Recall(1.00000), F1(0.98182) \n","Epoch 13, lr(1e-05) : Avg loss(0.019526) : TP(27),FN(0),FP(1),TN(26) : Accuracy(0.98148), Precision(0.96429), Recall(1.00000), F1(0.98182) \n","Epoch 14, lr(1e-05) : Avg loss(0.021515) : TP(27),FN(0),FP(1),TN(26) : Accuracy(0.98148), Precision(0.96429), Recall(1.00000), F1(0.98182) \n","Epoch 15, lr(1e-05) : Avg loss(0.022933) : TP(27),FN(0),FP(1),TN(26) : Accuracy(0.98148), Precision(0.96429), Recall(1.00000), F1(0.98182) \n","Epoch 16, lr(1e-05) : Avg loss(0.023543) : TP(27),FN(0),FP(1),TN(26) : Accuracy(0.98148), Precision(0.96429), Recall(1.00000), F1(0.98182) \n","Epoch 17, lr(1e-05) : Avg loss(0.026166) : TP(27),FN(0),FP(1),TN(26) : Accuracy(0.98148), Precision(0.96429), Recall(1.00000), F1(0.98182) \n","Epoch 18, lr(1e-05) : Avg loss(0.022318) : TP(27),FN(0),FP(1),TN(26) : Accuracy(0.98148), Precision(0.96429), Recall(1.00000), F1(0.98182) \n","Epoch 19, lr(1e-05) : Avg loss(0.027008) : TP(27),FN(0),FP(1),TN(26) : Accuracy(0.98148), Precision(0.96429), Recall(1.00000), F1(0.98182) \n","Epoch 20, lr(1e-05) : Avg loss(0.023170) : TP(27),FN(0),FP(1),TN(26) : Accuracy(0.98148), Precision(0.96429), Recall(1.00000), F1(0.98182) \n","Epoch 21, lr(1.0000000000000002e-06) : Avg loss(0.243050) : TP(27),FN(0),FP(1),TN(26) : Accuracy(0.98148), Precision(0.96429), Recall(1.00000), F1(0.98182) \n","Epoch 22, lr(1.0000000000000002e-06) : Avg loss(0.021970) : TP(27),FN(0),FP(1),TN(26) : Accuracy(0.98148), Precision(0.96429), Recall(1.00000), F1(0.98182) \n","Epoch 23, lr(1.0000000000000002e-06) : Avg loss(0.027905) : TP(27),FN(0),FP(1),TN(26) : Accuracy(0.98148), Precision(0.96429), Recall(1.00000), F1(0.98182) \n","Epoch 24, lr(1.0000000000000002e-06) : Avg loss(0.023531) : TP(27),FN(0),FP(1),TN(26) : Accuracy(0.98148), Precision(0.96429), Recall(1.00000), F1(0.98182) \n","Epoch 25, lr(1.0000000000000002e-06) : Avg loss(0.029613) : TP(27),FN(0),FP(1),TN(26) : Accuracy(0.98148), Precision(0.96429), Recall(1.00000), F1(0.98182) \n","Epoch 26, lr(1.0000000000000002e-06) : Avg loss(0.025212) : TP(27),FN(0),FP(1),TN(26) : Accuracy(0.98148), Precision(0.96429), Recall(1.00000), F1(0.98182) \n","Epoch 27, lr(1.0000000000000002e-06) : Avg loss(0.025275) : TP(27),FN(0),FP(1),TN(26) : Accuracy(0.98148), Precision(0.96429), Recall(1.00000), F1(0.98182) \n","Epoch 28, lr(1.0000000000000002e-06) : Avg loss(0.031731) : TP(27),FN(0),FP(1),TN(26) : Accuracy(0.98148), Precision(0.96429), Recall(1.00000), F1(0.98182) \n","Epoch 29, lr(1.0000000000000002e-06) : Avg loss(0.027772) : TP(27),FN(0),FP(1),TN(26) : Accuracy(0.98148), Precision(0.96429), Recall(1.00000), F1(0.98182) \n","Epoch 30, lr(1.0000000000000002e-06) : Avg loss(0.027866) : TP(27),FN(0),FP(1),TN(26) : Accuracy(0.98148), Precision(0.96429), Recall(1.00000), F1(0.98182) \n","Epoch 31, lr(1.0000000000000002e-07) : Avg loss(0.025704) : TP(27),FN(0),FP(1),TN(26) : Accuracy(0.98148), Precision(0.96429), Recall(1.00000), F1(0.98182) \n","Epoch 32, lr(1.0000000000000002e-07) : Avg loss(0.035680) : TP(27),FN(0),FP(1),TN(26) : Accuracy(0.98148), Precision(0.96429), Recall(1.00000), F1(0.98182) \n","Epoch 33, lr(1.0000000000000002e-07) : Avg loss(0.033459) : TP(27),FN(0),FP(1),TN(26) : Accuracy(0.98148), Precision(0.96429), Recall(1.00000), F1(0.98182) \n","Epoch 34, lr(1.0000000000000002e-07) : Avg loss(0.026955) : TP(27),FN(0),FP(1),TN(26) : Accuracy(0.98148), Precision(0.96429), Recall(1.00000), F1(0.98182) \n","Epoch 35, lr(1.0000000000000002e-07) : Avg loss(0.033406) : TP(27),FN(0),FP(1),TN(26) : Accuracy(0.98148), Precision(0.96429), Recall(1.00000), F1(0.98182) \n","Epoch 36, lr(1.0000000000000002e-07) : Avg loss(0.029144) : TP(27),FN(0),FP(1),TN(26) : Accuracy(0.98148), Precision(0.96429), Recall(1.00000), F1(0.98182) \n","Epoch 37, lr(1.0000000000000002e-07) : Avg loss(0.026927) : TP(27),FN(0),FP(1),TN(26) : Accuracy(0.98148), Precision(0.96429), Recall(1.00000), F1(0.98182) \n","Epoch 38, lr(1.0000000000000002e-07) : Avg loss(0.026023) : TP(27),FN(0),FP(1),TN(26) : Accuracy(0.98148), Precision(0.96429), Recall(1.00000), F1(0.98182) \n","Epoch 39, lr(1.0000000000000002e-07) : Avg loss(0.028174) : TP(27),FN(0),FP(1),TN(26) : Accuracy(0.98148), Precision(0.96429), Recall(1.00000), F1(0.98182) \n","Epoch 40, lr(1.0000000000000002e-07) : Avg loss(0.033489) : TP(27),FN(0),FP(1),TN(26) : Accuracy(0.98148), Precision(0.96429), Recall(1.00000), F1(0.98182) \n","==========================================\n","Training Time: 45.9457sec\n","Avg loss(0.198885) : TP(300),FN(0),FP(50),TN(250) : Accuracy(0.91667), Precision(0.85714), Recall(1.00000), F1(0.92308) \n","*** Best model (epoch:13) : Avg loss(0.198885) : TP(300),FN(0),FP(50),TN(250) : Accuracy(0.91667), Precision(0.85714), Recall(1.00000), F1(0.92308) \n","Inference Time: 2.3684sec\n","saved model name : /home/dataset/log/R18_csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0_B_A_H5_P0_R5_0716064731\n","300, 0, 50, 250, R18_csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0_B_A_H5_P0_R5_0716064731\n","----------------------------------------------------\n","CNN (R18)\n","Loss function (CrossEntropy) opt (Adam, 0.0001) lr_scheduler (MultiStepLR), [10, 20, 30], gamma(0.1)\n","random_seed (5, nX_read_flag (False)\n","Train (306), Validation (54), Test (600)\n","Epoch 1, lr(0.0001) : Avg loss(0.159513) : TP(21),FN(6),FP(0),TN(27) : Accuracy(0.88889), Precision(1.00000), Recall(0.77778), F1(0.87500) \n","Epoch 2, lr(0.0001) : Avg loss(0.036679) : TP(27),FN(0),FP(1),TN(26) : Accuracy(0.98148), Precision(0.96429), Recall(1.00000), F1(0.98182) \n","Epoch 3, lr(0.0001) : Avg loss(0.024726) : TP(27),FN(0),FP(1),TN(26) : Accuracy(0.98148), Precision(0.96429), Recall(1.00000), F1(0.98182) \n","Epoch 4, lr(0.0001) : Avg loss(0.014445) : TP(27),FN(0),FP(1),TN(26) : Accuracy(0.98148), Precision(0.96429), Recall(1.00000), F1(0.98182) \n","Epoch 5, lr(0.0001) : Avg loss(0.023364) : TP(27),FN(0),FP(1),TN(26) : Accuracy(0.98148), Precision(0.96429), Recall(1.00000), F1(0.98182) \n","Epoch 6, lr(0.0001) : Avg loss(0.178341) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 7, lr(0.0001) : Avg loss(0.026816) : TP(27),FN(0),FP(0),TN(27) : Accuracy(1.00000), Precision(1.00000), Recall(1.00000), F1(1.00000) \n","Epoch 8, lr(0.0001) : Avg loss(0.101631) : TP(23),FN(4),FP(0),TN(27) : Accuracy(0.92593), Precision(1.00000), Recall(0.85185), F1(0.92000) \n","Epoch 9, lr(0.0001) : Avg loss(0.031942) : TP(26),FN(1),FP(2),TN(25) : Accuracy(0.94444), Precision(0.92857), Recall(0.96296), F1(0.94545) \n","Epoch 10, lr(0.0001) : Avg loss(0.056735) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 11, lr(1e-05) : Avg loss(0.049987) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 12, lr(1e-05) : Avg loss(0.049227) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 13, lr(1e-05) : Avg loss(0.050903) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 14, lr(1e-05) : Avg loss(0.047572) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 15, lr(1e-05) : Avg loss(0.052439) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 16, lr(1e-05) : Avg loss(0.047585) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 17, lr(1e-05) : Avg loss(0.049528) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 18, lr(1e-05) : Avg loss(0.040895) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 19, lr(1e-05) : Avg loss(0.042240) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 20, lr(1e-05) : Avg loss(0.223111) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 21, lr(1.0000000000000002e-06) : Avg loss(0.035438) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 22, lr(1.0000000000000002e-06) : Avg loss(0.027948) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 23, lr(1.0000000000000002e-06) : Avg loss(0.028296) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 24, lr(1.0000000000000002e-06) : Avg loss(0.026349) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 25, lr(1.0000000000000002e-06) : Avg loss(0.023172) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 26, lr(1.0000000000000002e-06) : Avg loss(0.169457) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 27, lr(1.0000000000000002e-06) : Avg loss(0.034497) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 28, lr(1.0000000000000002e-06) : Avg loss(0.031614) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 29, lr(1.0000000000000002e-06) : Avg loss(0.035792) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 30, lr(1.0000000000000002e-06) : Avg loss(0.045529) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 31, lr(1.0000000000000002e-07) : Avg loss(0.037302) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 32, lr(1.0000000000000002e-07) : Avg loss(0.034112) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 33, lr(1.0000000000000002e-07) : Avg loss(0.045070) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 34, lr(1.0000000000000002e-07) : Avg loss(0.031920) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 35, lr(1.0000000000000002e-07) : Avg loss(0.125961) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 36, lr(1.0000000000000002e-07) : Avg loss(0.023262) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 37, lr(1.0000000000000002e-07) : Avg loss(0.035382) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 38, lr(1.0000000000000002e-07) : Avg loss(0.030230) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 39, lr(1.0000000000000002e-07) : Avg loss(0.035396) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","Epoch 40, lr(1.0000000000000002e-07) : Avg loss(0.036987) : TP(27),FN(0),FP(2),TN(25) : Accuracy(0.96296), Precision(0.93103), Recall(1.00000), F1(0.96429) \n","==========================================\n","Training Time: 46.1834sec\n","Avg loss(0.202225) : TP(299),FN(1),FP(48),TN(252) : Accuracy(0.91833), Precision(0.86167), Recall(0.99667), F1(0.92427) \n","*** Best model (epoch:4) : Avg loss(0.202225) : TP(299),FN(1),FP(48),TN(252) : Accuracy(0.91833), Precision(0.86167), Recall(0.99667), F1(0.92427) \n","Inference Time: 2.3706sec\n","saved model name : /home/dataset/log/R18_csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0_B_A_H5_P0_R5_0716064820\n","299, 1, 48, 252, R18_csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0_B_A_H5_P0_R5_0716064820\n","----------------------------------------------------\n","290\t10\t12\t288\tR18_csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0_B_A_H5_P0_R31_0716064414\n","290\t10\t16\t284\tR18_csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0_B_A_H5_P0_R31_0716064503\n","297\t3\t47\t253\tR18_csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0_B_A_H5_P0_R42_0716064553\n","300\t0\t65\t235\tR18_csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0_B_A_H5_P0_R42_0716064642\n","300\t0\t50\t250\tR18_csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0_B_A_H5_P0_R5_0716064731\n","299\t1\t48\t252\tR18_csi(1c)_AmFall_402_SDS_V0.10_O10_img_4.0_B_A_H5_P0_R5_0716064820\n","\n"]}]}]}